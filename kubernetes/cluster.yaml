apiVersion: v1
items:
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-08-08T17:30:13Z"
    generateName: ingress-app-ingress-nginx-controller-544f5dfc8f-
    labels:
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: ingress-app
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: ingress-nginx
      app.kubernetes.io/part-of: ingress-nginx
      app.kubernetes.io/version: 1.11.1
      helm.sh/chart: ingress-nginx-4.11.1
      pod-template-hash: 544f5dfc8f
    name: ingress-app-ingress-nginx-controller-544f5dfc8f-5mkc8
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: ingress-app-ingress-nginx-controller-544f5dfc8f
      uid: b51212ec-9672-4663-9c71-ee97b342d70b
    resourceVersion: "26034"
    uid: 7c40e53c-3d60-45e9-b293-02edefe3f3d3
  spec:
    containers:
    - args:
      - /nginx-ingress-controller
      - --publish-service=$(POD_NAMESPACE)/ingress-app-ingress-nginx-controller
      - --election-id=ingress-app-ingress-nginx-leader
      - --controller-class=k8s.io/ingress-nginx
      - --ingress-class=nginx
      - --configmap=$(POD_NAMESPACE)/ingress-app-ingress-nginx-controller
      - --validating-webhook=:8443
      - --validating-webhook-certificate=/usr/local/certificates/cert
      - --validating-webhook-key=/usr/local/certificates/key
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: LD_PRELOAD
        value: /usr/local/lib/libmimalloc.so
      image: registry.k8s.io/ingress-nginx/controller:v1.11.1@sha256:e6439a12b52076965928e83b7b56aae6731231677b01e81818bce7fa5c60161a
      imagePullPolicy: IfNotPresent
      lifecycle:
        preStop:
          exec:
            command:
            - /wait-shutdown
      livenessProbe:
        failureThreshold: 5
        httpGet:
          path: /healthz
          port: 10254
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: controller
      ports:
      - containerPort: 80
        name: http
        protocol: TCP
      - containerPort: 443
        name: https
        protocol: TCP
      - containerPort: 10254
        name: metrics
        protocol: TCP
      - containerPort: 8443
        name: webhook
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: 10254
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        requests:
          cpu: 100m
          memory: 90Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          add:
          - NET_BIND_SERVICE
          drop:
          - ALL
        readOnlyRootFilesystem: false
        runAsNonRoot: true
        runAsUser: 101
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /usr/local/certificates/
        name: webhook-cert
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-bwl9j
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: minikube
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: ingress-app-ingress-nginx
    serviceAccountName: ingress-app-ingress-nginx
    terminationGracePeriodSeconds: 300
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: webhook-cert
      secret:
        defaultMode: 420
        secretName: ingress-app-ingress-nginx-admission
    - name: kube-api-access-bwl9j
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:49Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-08-08T17:30:13Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:58:26Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:58:26Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-08-08T17:30:13Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://74e6beecc512a268d4645e468aea4e8331671d680b7516b38b2278be4115210c
      image: sha256:5a3c471280784f5608f93a85c51b1d34b68689d20540689077010c90f137701a
      imageID: docker-pullable://registry.k8s.io/ingress-nginx/controller@sha256:e6439a12b52076965928e83b7b56aae6731231677b01e81818bce7fa5c60161a
      lastState:
        terminated:
          containerID: docker://5b2e304c23004cb05d24ab954b0f41c9ffdfaba4405c424c55725f3cabc112a8
          exitCode: 255
          finishedAt: "2024-08-11T12:57:38Z"
          reason: Error
          startedAt: "2024-08-11T02:16:02Z"
      name: controller
      ready: true
      restartCount: 3
      started: true
      state:
        running:
          startedAt: "2024-08-11T12:57:49Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Running
    podIP: 10.244.0.136
    podIPs:
    - ip: 10.244.0.136
    qosClass: Burstable
    startTime: "2024-08-08T17:30:13Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-08-11T14:54:55Z"
    generateName: ml-api-deployment-548d698969-
    labels:
      app: ml-api
      pod-template-hash: 548d698969
    name: ml-api-deployment-548d698969-scp5t
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: ml-api-deployment-548d698969
      uid: 12c9a921-aef1-4900-8f71-5d2ee2da8b74
    resourceVersion: "34154"
    uid: 73867d4c-a677-4458-925c-ca5710350778
  spec:
    containers:
    - env:
      - name: FLASK_ENV
        value: production
      image: shreyas2204/ml-api:latest
      imagePullPolicy: Always
      name: ml-api
      ports:
      - containerPort: 5000
        protocol: TCP
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-5m5qq
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: minikube
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-5m5qq
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T14:55:16Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T14:54:55Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T14:55:16Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T14:55:16Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T14:54:55Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://125a84865852c06f2582b17fac2840e70d68b5879c057346850acefd40ef04cc
      image: shreyas2204/ml-api:latest
      imageID: docker-pullable://shreyas2204/ml-api@sha256:d98e7b6f81fab82081b3d4cd298e607934867cfb3798a0d7772ba075ce748973
      lastState: {}
      name: ml-api
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-08-11T14:55:16Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Running
    podIP: 10.244.0.144
    podIPs:
    - ip: 10.244.0.144
    qosClass: BestEffort
    startTime: "2024-08-11T14:54:55Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-08-08T13:12:25Z"
    generateName: nodeapp-deployment-6cc654cb66-
    labels:
      app: nodeapp
      pod-template-hash: 6cc654cb66
    name: nodeapp-deployment-6cc654cb66-69vjq
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: nodeapp-deployment-6cc654cb66
      uid: 37defdaa-8d13-440f-90b5-6a469b04bb6d
    resourceVersion: "25894"
    uid: ed4e141c-bcdd-4d4f-a430-c66e6791f646
  spec:
    containers:
    - image: shreyas2204/my-node-app
      imagePullPolicy: Always
      name: nodeserver
      ports:
      - containerPort: 4000
        protocol: TCP
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-8q6jk
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: minikube
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-8q6jk
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:53Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-08-08T13:12:25Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:53Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:53Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-08-08T13:12:25Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://abd2afa903ec76e3453de7f161a414fed22f8105f7c5b44007531a22835d645c
      image: shreyas2204/my-node-app:latest
      imageID: docker-pullable://shreyas2204/my-node-app@sha256:8911b3e826d28662da55da0f3f1a8359330873a052c946b96ee510039e750493
      lastState:
        terminated:
          containerID: docker://cca419d3114673ba86304dd341cb925dc1154728b67ed19648dd99eb890d4e9c
          exitCode: 255
          finishedAt: "2024-08-11T12:57:38Z"
          reason: Error
          startedAt: "2024-08-11T02:16:04Z"
      name: nodeserver
      ready: true
      restartCount: 3
      started: true
      state:
        running:
          startedAt: "2024-08-11T12:57:53Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Running
    podIP: 10.244.0.130
    podIPs:
    - ip: 10.244.0.130
    qosClass: BestEffort
    startTime: "2024-08-08T13:12:25Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-08-10T06:03:08Z"
    generateName: nodeapp-deployment-6cc654cb66-
    labels:
      app: nodeapp
      pod-template-hash: 6cc654cb66
    name: nodeapp-deployment-6cc654cb66-n5zw5
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: nodeapp-deployment-6cc654cb66
      uid: 37defdaa-8d13-440f-90b5-6a469b04bb6d
    resourceVersion: "25889"
    uid: a7f9e477-5442-4f94-9399-944142ddb594
  spec:
    containers:
    - image: shreyas2204/my-node-app
      imagePullPolicy: Always
      name: nodeserver
      ports:
      - containerPort: 4000
        protocol: TCP
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-vlh2g
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: minikube
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-vlh2g
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:51Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-08-10T06:03:08Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:51Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:51Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-08-10T06:03:08Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://5536cbe7afb2d20c39e142dbc866878cbeb8e9029f2907b1af878a9a15b2b09b
      image: shreyas2204/my-node-app:latest
      imageID: docker-pullable://shreyas2204/my-node-app@sha256:8911b3e826d28662da55da0f3f1a8359330873a052c946b96ee510039e750493
      lastState:
        terminated:
          containerID: docker://2767b98ea409f19e8f150ce6a4eefedf016450302b895d564ceeea1876e40f7b
          exitCode: 255
          finishedAt: "2024-08-11T12:57:38Z"
          reason: Error
          startedAt: "2024-08-11T02:16:12Z"
      name: nodeserver
      ready: true
      restartCount: 2
      started: true
      state:
        running:
          startedAt: "2024-08-11T12:57:50Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Running
    podIP: 10.244.0.128
    podIPs:
    - ip: 10.244.0.128
    qosClass: BestEffort
    startTime: "2024-08-10T06:03:08Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-08-10T06:03:08Z"
    generateName: nodeapp-deployment-6cc654cb66-
    labels:
      app: nodeapp
      pod-template-hash: 6cc654cb66
    name: nodeapp-deployment-6cc654cb66-st2gr
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: nodeapp-deployment-6cc654cb66
      uid: 37defdaa-8d13-440f-90b5-6a469b04bb6d
    resourceVersion: "25927"
    uid: b639cbf9-c43d-4128-bcf8-3f21c7e049dd
  spec:
    containers:
    - image: shreyas2204/my-node-app
      imagePullPolicy: Always
      name: nodeserver
      ports:
      - containerPort: 4000
        protocol: TCP
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-chkm9
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: minikube
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-chkm9
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:59Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-08-10T06:03:08Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:59Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:59Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-08-10T06:03:08Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://e43f02166171d3b75d986b1fe3344b255c18146ca65ec04294a3dc7e18af1618
      image: shreyas2204/my-node-app:latest
      imageID: docker-pullable://shreyas2204/my-node-app@sha256:8911b3e826d28662da55da0f3f1a8359330873a052c946b96ee510039e750493
      lastState:
        terminated:
          containerID: docker://2847db6a42e34042baf68e6a78cc3ddc0e6e15a2c9e7300e06975d77f886d36e
          exitCode: 255
          finishedAt: "2024-08-11T12:57:38Z"
          reason: Error
          startedAt: "2024-08-11T02:16:06Z"
      name: nodeserver
      ready: true
      restartCount: 2
      started: true
      state:
        running:
          startedAt: "2024-08-11T12:57:59Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Running
    podIP: 10.244.0.138
    podIPs:
    - ip: 10.244.0.138
    qosClass: BestEffort
    startTime: "2024-08-10T06:03:08Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-08-10T06:03:08Z"
    generateName: nodeapp-deployment-6cc654cb66-
    labels:
      app: nodeapp
      pod-template-hash: 6cc654cb66
    name: nodeapp-deployment-6cc654cb66-twvxn
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: nodeapp-deployment-6cc654cb66
      uid: 37defdaa-8d13-440f-90b5-6a469b04bb6d
    resourceVersion: "25916"
    uid: f177a407-3201-446b-9477-1634554b6d3c
  spec:
    containers:
    - image: shreyas2204/my-node-app
      imagePullPolicy: Always
      name: nodeserver
      ports:
      - containerPort: 4000
        protocol: TCP
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-p2pvf
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: minikube
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-p2pvf
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:57Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-08-10T06:03:08Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:57Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:57Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-08-10T06:03:08Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://c2c9f6b094780534dce4a2bf58ad84706a8f99046bc81abae370600dc57e4aae
      image: shreyas2204/my-node-app:latest
      imageID: docker-pullable://shreyas2204/my-node-app@sha256:8911b3e826d28662da55da0f3f1a8359330873a052c946b96ee510039e750493
      lastState:
        terminated:
          containerID: docker://2f128b1fdf6fa8e77b0571c6fc9d18ae1bb20d13053fb49ed2155b582d551436
          exitCode: 255
          finishedAt: "2024-08-11T12:57:38Z"
          reason: Error
          startedAt: "2024-08-11T02:16:08Z"
      name: nodeserver
      ready: true
      restartCount: 2
      started: true
      state:
        running:
          startedAt: "2024-08-11T12:57:57Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Running
    podIP: 10.244.0.137
    podIPs:
    - ip: 10.244.0.137
    qosClass: BestEffort
    startTime: "2024-08-10T06:03:08Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-08-10T06:03:08Z"
    generateName: nodeapp-deployment-6cc654cb66-
    labels:
      app: nodeapp
      pod-template-hash: 6cc654cb66
    name: nodeapp-deployment-6cc654cb66-x9jql
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: nodeapp-deployment-6cc654cb66
      uid: 37defdaa-8d13-440f-90b5-6a469b04bb6d
    resourceVersion: "25902"
    uid: 721e9534-aa9b-44f3-a009-d9d02313cea1
  spec:
    containers:
    - image: shreyas2204/my-node-app
      imagePullPolicy: Always
      name: nodeserver
      ports:
      - containerPort: 4000
        protocol: TCP
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-cxpf9
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: minikube
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-cxpf9
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:55Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-08-10T06:03:08Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:55Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:55Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-08-10T06:03:08Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://215bbff69824412e6da88e6028af4425cd695bf3515ae17feecbebb23d44266c
      image: shreyas2204/my-node-app:latest
      imageID: docker-pullable://shreyas2204/my-node-app@sha256:8911b3e826d28662da55da0f3f1a8359330873a052c946b96ee510039e750493
      lastState:
        terminated:
          containerID: docker://614c8740865220047062572eb3016c2b57c35cc1abfd95b792dd1ab00467215a
          exitCode: 255
          finishedAt: "2024-08-11T12:57:38Z"
          reason: Error
          startedAt: "2024-08-11T02:16:11Z"
      name: nodeserver
      ready: true
      restartCount: 2
      started: true
      state:
        running:
          startedAt: "2024-08-11T12:57:55Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Running
    podIP: 10.244.0.135
    podIPs:
    - ip: 10.244.0.135
    qosClass: BestEffort
    startTime: "2024-08-10T06:03:08Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-08-08T16:24:08Z"
    generateName: ingress-nginx-admission-create-
    labels:
      app.kubernetes.io/component: admission-webhook
      app.kubernetes.io/instance: ingress-nginx
      app.kubernetes.io/name: ingress-nginx
      batch.kubernetes.io/controller-uid: f8296098-5c81-40c6-b81f-4b2d97c8be53
      batch.kubernetes.io/job-name: ingress-nginx-admission-create
      controller-uid: f8296098-5c81-40c6-b81f-4b2d97c8be53
      job-name: ingress-nginx-admission-create
    name: ingress-nginx-admission-create-8lrtb
    namespace: ingress-nginx
    ownerReferences:
    - apiVersion: batch/v1
      blockOwnerDeletion: true
      controller: true
      kind: Job
      name: ingress-nginx-admission-create
      uid: f8296098-5c81-40c6-b81f-4b2d97c8be53
    resourceVersion: "19384"
    uid: dba753cf-503f-4fb6-9e45-eb5331e06b6e
  spec:
    containers:
    - args:
      - create
      - --host=ingress-nginx-controller-admission,ingress-nginx-controller-admission.$(POD_NAMESPACE).svc
      - --namespace=$(POD_NAMESPACE)
      - --secret-name=ingress-nginx-admission
      env:
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.4.1@sha256:36d05b4077fb8e3d13663702fa337f124675ba8667cbd949c03a8e8ea6fa4366
      imagePullPolicy: IfNotPresent
      name: create
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-jq7jc
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: minikube
    nodeSelector:
      kubernetes.io/os: linux
      minikube.k8s.io/primary: "true"
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: OnFailure
    schedulerName: default-scheduler
    securityContext:
      runAsNonRoot: true
      runAsUser: 2000
    serviceAccount: ingress-nginx-admission
    serviceAccountName: ingress-nginx-admission
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-jq7jc
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-08-08T16:24:10Z"
      status: "False"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-08-08T16:24:08Z"
      reason: PodCompleted
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-08-08T16:24:08Z"
      reason: PodCompleted
      status: "False"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-08-08T16:24:08Z"
      reason: PodCompleted
      status: "False"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-08-08T16:24:08Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://d0fad1110f3175e3ab365e34be2b7a95651080fe45ef957f255c25c7a5786d82
      image: sha256:684c5ea3b61b299cd4e713c10bfd8989341da91f6175e2e6e502869c0781fb66
      imageID: docker-pullable://registry.k8s.io/ingress-nginx/kube-webhook-certgen@sha256:36d05b4077fb8e3d13663702fa337f124675ba8667cbd949c03a8e8ea6fa4366
      lastState: {}
      name: create
      ready: false
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: docker://d0fad1110f3175e3ab365e34be2b7a95651080fe45ef957f255c25c7a5786d82
          exitCode: 0
          finishedAt: "2024-08-08T16:24:09Z"
          reason: Completed
          startedAt: "2024-08-08T16:24:09Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Succeeded
    qosClass: BestEffort
    startTime: "2024-08-08T16:24:08Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-08-08T16:24:08Z"
    generateName: ingress-nginx-admission-patch-
    labels:
      app.kubernetes.io/component: admission-webhook
      app.kubernetes.io/instance: ingress-nginx
      app.kubernetes.io/name: ingress-nginx
      batch.kubernetes.io/controller-uid: 1deee006-032e-4a76-aeba-46e7e12ddb68
      batch.kubernetes.io/job-name: ingress-nginx-admission-patch
      controller-uid: 1deee006-032e-4a76-aeba-46e7e12ddb68
      job-name: ingress-nginx-admission-patch
    name: ingress-nginx-admission-patch-k97lm
    namespace: ingress-nginx
    ownerReferences:
    - apiVersion: batch/v1
      blockOwnerDeletion: true
      controller: true
      kind: Job
      name: ingress-nginx-admission-patch
      uid: 1deee006-032e-4a76-aeba-46e7e12ddb68
    resourceVersion: "19383"
    uid: 605478f0-9075-4b34-823f-aef84daeb1e3
  spec:
    containers:
    - args:
      - patch
      - --webhook-name=ingress-nginx-admission
      - --namespace=$(POD_NAMESPACE)
      - --patch-mutating=false
      - --secret-name=ingress-nginx-admission
      - --patch-failure-policy=Fail
      env:
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.4.1@sha256:36d05b4077fb8e3d13663702fa337f124675ba8667cbd949c03a8e8ea6fa4366
      imagePullPolicy: IfNotPresent
      name: patch
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-tnp6w
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: minikube
    nodeSelector:
      kubernetes.io/os: linux
      minikube.k8s.io/primary: "true"
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: OnFailure
    schedulerName: default-scheduler
    securityContext:
      runAsNonRoot: true
      runAsUser: 2000
    serviceAccount: ingress-nginx-admission
    serviceAccountName: ingress-nginx-admission
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-tnp6w
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-08-08T16:24:11Z"
      status: "False"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-08-08T16:24:08Z"
      reason: PodCompleted
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-08-08T16:24:08Z"
      reason: PodCompleted
      status: "False"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-08-08T16:24:08Z"
      reason: PodCompleted
      status: "False"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-08-08T16:24:08Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://4a57ac833585bddf852557c5404c6fc28a91fca323c1294535c62ff2b1a062e0
      image: sha256:684c5ea3b61b299cd4e713c10bfd8989341da91f6175e2e6e502869c0781fb66
      imageID: docker-pullable://registry.k8s.io/ingress-nginx/kube-webhook-certgen@sha256:36d05b4077fb8e3d13663702fa337f124675ba8667cbd949c03a8e8ea6fa4366
      lastState: {}
      name: patch
      ready: false
      restartCount: 1
      started: false
      state:
        terminated:
          containerID: docker://4a57ac833585bddf852557c5404c6fc28a91fca323c1294535c62ff2b1a062e0
          exitCode: 0
          finishedAt: "2024-08-08T16:24:09Z"
          reason: Completed
          startedAt: "2024-08-08T16:24:09Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Succeeded
    qosClass: BestEffort
    startTime: "2024-08-08T16:24:08Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-08-10T11:31:41Z"
    generateName: ingress-nginx-controller-768f948f8f-
    labels:
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: ingress-nginx
      app.kubernetes.io/name: ingress-nginx
      gcp-auth-skip-secret: "true"
      pod-template-hash: 768f948f8f
    name: ingress-nginx-controller-768f948f8f-fkfw5
    namespace: ingress-nginx
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: ingress-nginx-controller-768f948f8f
      uid: 2597efdf-f9b9-4984-a2da-858069135674
    resourceVersion: "26060"
    uid: 391abca1-65e2-45d5-869e-fc624da096d8
  spec:
    containers:
    - args:
      - /nginx-ingress-controller
      - --election-id=ingress-nginx-leader
      - --controller-class=k8s.io/ingress-nginx
      - --watch-ingress-without-class=true
      - --configmap=$(POD_NAMESPACE)/ingress-nginx-controller
      - --tcp-services-configmap=$(POD_NAMESPACE)/tcp-services
      - --udp-services-configmap=$(POD_NAMESPACE)/udp-services
      - --validating-webhook=:8443
      - --validating-webhook-certificate=/usr/local/certificates/cert
      - --validating-webhook-key=/usr/local/certificates/key
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: LD_PRELOAD
        value: /usr/local/lib/libmimalloc.so
      image: registry.k8s.io/ingress-nginx/controller:v1.10.1@sha256:e24f39d3eed6bcc239a56f20098878845f62baa34b9f2be2fd2c38ce9fb0f29e
      imagePullPolicy: IfNotPresent
      lifecycle:
        preStop:
          exec:
            command:
            - /wait-shutdown
      livenessProbe:
        failureThreshold: 5
        httpGet:
          path: /healthz
          port: 10254
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: controller
      ports:
      - containerPort: 80
        hostPort: 80
        name: http
        protocol: TCP
      - containerPort: 443
        hostPort: 443
        name: https
        protocol: TCP
      - containerPort: 8443
        name: webhook
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: 10254
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        requests:
          cpu: 100m
          memory: 90Mi
      securityContext:
        allowPrivilegeEscalation: true
        capabilities:
          add:
          - NET_BIND_SERVICE
          drop:
          - ALL
        runAsUser: 101
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /usr/local/certificates/
        name: webhook-cert
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-ftpnx
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: minikube
    nodeSelector:
      kubernetes.io/os: linux
      minikube.k8s.io/primary: "true"
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: ingress-nginx
    serviceAccountName: ingress-nginx
    terminationGracePeriodSeconds: 0
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
      operator: Equal
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: webhook-cert
      secret:
        defaultMode: 420
        secretName: ingress-nginx-admission
    - name: kube-api-access-ftpnx
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:49Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-08-10T11:31:43Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:58:32Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:58:32Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-08-10T11:31:43Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://ca8b665f26f5cde36f22dfeb577b3ba7f950a5e6369c448ab7da7188d763d68f
      image: sha256:ee54966f3891d75b255d160236368a4f9d3b588d32fb44bd04aea5101143e829
      imageID: docker-pullable://registry.k8s.io/ingress-nginx/controller@sha256:e24f39d3eed6bcc239a56f20098878845f62baa34b9f2be2fd2c38ce9fb0f29e
      lastState:
        terminated:
          containerID: docker://02a708938f3434211c0ab9ca1f6adc0c97b0240ea44b78ada237d010cba6248d
          exitCode: 255
          finishedAt: "2024-08-11T12:57:38Z"
          reason: Error
          startedAt: "2024-08-11T02:16:02Z"
      name: controller
      ready: true
      restartCount: 2
      started: true
      state:
        running:
          startedAt: "2024-08-11T12:57:48Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Running
    podIP: 10.244.0.129
    podIPs:
    - ip: 10.244.0.129
    qosClass: Burstable
    startTime: "2024-08-10T11:31:43Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-08-08T13:10:31Z"
    generateName: coredns-7db6d8ff4d-
    labels:
      k8s-app: kube-dns
      pod-template-hash: 7db6d8ff4d
    name: coredns-7db6d8ff4d-tjqfq
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: coredns-7db6d8ff4d
      uid: a73403f7-0086-44a7-8bec-c872be863ef9
    resourceVersion: "26053"
    uid: cd306b39-aa42-4d33-a349-4d314cbf549c
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: k8s-app
                operator: In
                values:
                - kube-dns
            topologyKey: kubernetes.io/hostname
          weight: 100
    containers:
    - args:
      - -conf
      - /etc/coredns/Corefile
      image: registry.k8s.io/coredns/coredns:v1.11.1
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 5
        httpGet:
          path: /health
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: coredns
      ports:
      - containerPort: 53
        name: dns
        protocol: UDP
      - containerPort: 53
        name: dns-tcp
        protocol: TCP
      - containerPort: 9153
        name: metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /ready
          port: 8181
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        limits:
          memory: 170Mi
        requests:
          cpu: 100m
          memory: 70Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          add:
          - NET_BIND_SERVICE
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/coredns
        name: config-volume
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-s62x9
        readOnly: true
    dnsPolicy: Default
    enableServiceLinks: true
    nodeName: minikube
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: coredns
    serviceAccountName: coredns
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/control-plane
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        items:
        - key: Corefile
          path: Corefile
        name: coredns
      name: config-volume
    - name: kube-api-access-s62x9
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:49Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-08-08T13:10:31Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:58:29Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:58:29Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-08-08T13:10:31Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://baebd99bd3dcae19fdf9b5a389e297530be15a9bc3d6bcdfc32f92737e6b6c44
      image: registry.k8s.io/coredns/coredns:v1.11.1
      imageID: docker-pullable://registry.k8s.io/coredns/coredns@sha256:1eeb4c7316bacb1d4c8ead65571cd92dd21e27359f0d4917f1a5822a73b75db1
      lastState:
        terminated:
          containerID: docker://e5e2de3a44bdffba3858c42b40d508eed50a61e5c2aad91ce7b04a9a5e6e85cf
          exitCode: 255
          finishedAt: "2024-08-11T12:57:38Z"
          reason: Error
          startedAt: "2024-08-11T02:16:02Z"
      name: coredns
      ready: true
      restartCount: 3
      started: true
      state:
        running:
          startedAt: "2024-08-11T12:57:48Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Running
    podIP: 10.244.0.131
    podIPs:
    - ip: 10.244.0.131
    qosClass: Burstable
    startTime: "2024-08-08T13:10:31Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubeadm.kubernetes.io/etcd.advertise-client-urls: https://192.168.49.2:2379
      kubernetes.io/config.hash: 063d6b9688927e601f52fd818d1305c5
      kubernetes.io/config.mirror: 063d6b9688927e601f52fd818d1305c5
      kubernetes.io/config.seen: "2024-08-08T13:10:16.657143927Z"
      kubernetes.io/config.source: file
    creationTimestamp: "2024-08-08T13:10:16Z"
    labels:
      component: etcd
      tier: control-plane
    name: etcd-minikube
    namespace: kube-system
    ownerReferences:
    - apiVersion: v1
      controller: true
      kind: Node
      name: minikube
      uid: f9fe5e0a-ec7a-4ec2-90f9-a25cc3fdc836
    resourceVersion: "25907"
    uid: 2bc345d7-ba65-4530-9b37-a00bceb1db8f
  spec:
    containers:
    - command:
      - etcd
      - --advertise-client-urls=https://192.168.49.2:2379
      - --cert-file=/var/lib/minikube/certs/etcd/server.crt
      - --client-cert-auth=true
      - --data-dir=/var/lib/minikube/etcd
      - --experimental-initial-corrupt-check=true
      - --experimental-watch-progress-notify-interval=5s
      - --initial-advertise-peer-urls=https://192.168.49.2:2380
      - --initial-cluster=minikube=https://192.168.49.2:2380
      - --key-file=/var/lib/minikube/certs/etcd/server.key
      - --listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379
      - --listen-metrics-urls=http://127.0.0.1:2381
      - --listen-peer-urls=https://192.168.49.2:2380
      - --name=minikube
      - --peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt
      - --peer-client-cert-auth=true
      - --peer-key-file=/var/lib/minikube/certs/etcd/peer.key
      - --peer-trusted-ca-file=/var/lib/minikube/certs/etcd/ca.crt
      - --proxy-refresh-interval=70000
      - --snapshot-count=10000
      - --trusted-ca-file=/var/lib/minikube/certs/etcd/ca.crt
      image: registry.k8s.io/etcd:3.5.12-0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 8
        httpGet:
          host: 127.0.0.1
          path: /health?exclude=NOSPACE&serializable=true
          port: 2381
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      name: etcd
      resources:
        requests:
          cpu: 100m
          memory: 100Mi
      startupProbe:
        failureThreshold: 24
        httpGet:
          host: 127.0.0.1
          path: /health?serializable=false
          port: 2381
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/minikube/etcd
        name: etcd-data
      - mountPath: /var/lib/minikube/certs/etcd
        name: etcd-certs
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: minikube
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      seccompProfile:
        type: RuntimeDefault
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    volumes:
    - hostPath:
        path: /var/lib/minikube/certs/etcd
        type: DirectoryOrCreate
      name: etcd-certs
    - hostPath:
        path: /var/lib/minikube/etcd
        type: DirectoryOrCreate
      name: etcd-data
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:46Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:45Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:57Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:57Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:45Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://cb4f5bd93a8fc2eab51b665e329ff2592c1bacfffdcc2391028ac5d3b7304e9b
      image: registry.k8s.io/etcd:3.5.12-0
      imageID: docker-pullable://registry.k8s.io/etcd@sha256:44a8e24dcbba3470ee1fee21d5e88d128c936e9b55d4bc51fbef8086f8ed123b
      lastState:
        terminated:
          containerID: docker://f500a434b5f01b3dc1e446e61332f3b371f743aed306d49afba8f538e7d5cd22
          exitCode: 255
          finishedAt: "2024-08-11T12:57:38Z"
          reason: Error
          startedAt: "2024-08-11T02:15:57Z"
      name: etcd
      ready: true
      restartCount: 3
      started: true
      state:
        running:
          startedAt: "2024-08-11T12:57:45Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Running
    podIP: 192.168.49.2
    podIPs:
    - ip: 192.168.49.2
    qosClass: Burstable
    startTime: "2024-08-11T12:57:45Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubeadm.kubernetes.io/kube-apiserver.advertise-address.endpoint: 192.168.49.2:8443
      kubernetes.io/config.hash: 3c555f828409b009ebee39fdbedfcac0
      kubernetes.io/config.mirror: 3c555f828409b009ebee39fdbedfcac0
      kubernetes.io/config.seen: "2024-08-08T13:10:16.657148607Z"
      kubernetes.io/config.source: file
    creationTimestamp: "2024-08-08T13:10:16Z"
    labels:
      component: kube-apiserver
      tier: control-plane
    name: kube-apiserver-minikube
    namespace: kube-system
    ownerReferences:
    - apiVersion: v1
      controller: true
      kind: Node
      name: minikube
      uid: f9fe5e0a-ec7a-4ec2-90f9-a25cc3fdc836
    resourceVersion: "25909"
    uid: 749998dd-3d1a-4641-abf2-ac30b420a3a2
  spec:
    containers:
    - command:
      - kube-apiserver
      - --advertise-address=192.168.49.2
      - --allow-privileged=true
      - --authorization-mode=Node,RBAC
      - --client-ca-file=/var/lib/minikube/certs/ca.crt
      - --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota
      - --enable-bootstrap-token-auth=true
      - --etcd-cafile=/var/lib/minikube/certs/etcd/ca.crt
      - --etcd-certfile=/var/lib/minikube/certs/apiserver-etcd-client.crt
      - --etcd-keyfile=/var/lib/minikube/certs/apiserver-etcd-client.key
      - --etcd-servers=https://127.0.0.1:2379
      - --kubelet-client-certificate=/var/lib/minikube/certs/apiserver-kubelet-client.crt
      - --kubelet-client-key=/var/lib/minikube/certs/apiserver-kubelet-client.key
      - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
      - --proxy-client-cert-file=/var/lib/minikube/certs/front-proxy-client.crt
      - --proxy-client-key-file=/var/lib/minikube/certs/front-proxy-client.key
      - --requestheader-allowed-names=front-proxy-client
      - --requestheader-client-ca-file=/var/lib/minikube/certs/front-proxy-ca.crt
      - --requestheader-extra-headers-prefix=X-Remote-Extra-
      - --requestheader-group-headers=X-Remote-Group
      - --requestheader-username-headers=X-Remote-User
      - --secure-port=8443
      - --service-account-issuer=https://kubernetes.default.svc.cluster.local
      - --service-account-key-file=/var/lib/minikube/certs/sa.pub
      - --service-account-signing-key-file=/var/lib/minikube/certs/sa.key
      - --service-cluster-ip-range=10.96.0.0/12
      - --tls-cert-file=/var/lib/minikube/certs/apiserver.crt
      - --tls-private-key-file=/var/lib/minikube/certs/apiserver.key
      image: registry.k8s.io/kube-apiserver:v1.30.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 8
        httpGet:
          host: 192.168.49.2
          path: /livez
          port: 8443
          scheme: HTTPS
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      name: kube-apiserver
      readinessProbe:
        failureThreshold: 3
        httpGet:
          host: 192.168.49.2
          path: /readyz
          port: 8443
          scheme: HTTPS
        periodSeconds: 1
        successThreshold: 1
        timeoutSeconds: 15
      resources:
        requests:
          cpu: 250m
      startupProbe:
        failureThreshold: 24
        httpGet:
          host: 192.168.49.2
          path: /livez
          port: 8443
          scheme: HTTPS
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/ssl/certs
        name: ca-certs
        readOnly: true
      - mountPath: /etc/ca-certificates
        name: etc-ca-certificates
        readOnly: true
      - mountPath: /var/lib/minikube/certs
        name: k8s-certs
        readOnly: true
      - mountPath: /usr/local/share/ca-certificates
        name: usr-local-share-ca-certificates
        readOnly: true
      - mountPath: /usr/share/ca-certificates
        name: usr-share-ca-certificates
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: minikube
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      seccompProfile:
        type: RuntimeDefault
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    volumes:
    - hostPath:
        path: /etc/ssl/certs
        type: DirectoryOrCreate
      name: ca-certs
    - hostPath:
        path: /etc/ca-certificates
        type: DirectoryOrCreate
      name: etc-ca-certificates
    - hostPath:
        path: /var/lib/minikube/certs
        type: DirectoryOrCreate
      name: k8s-certs
    - hostPath:
        path: /usr/local/share/ca-certificates
        type: DirectoryOrCreate
      name: usr-local-share-ca-certificates
    - hostPath:
        path: /usr/share/ca-certificates
        type: DirectoryOrCreate
      name: usr-share-ca-certificates
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:46Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:45Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:57Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:57Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:45Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://83bcff2daa92362b7232b60da4fa877c05eb9eaa5ea92f6ba2d09378bf6dfa23
      image: registry.k8s.io/kube-apiserver:v1.30.0
      imageID: docker-pullable://registry.k8s.io/kube-apiserver@sha256:6b8e197b2d39c321189a475ac755a77896e34b56729425590fbc99f3a96468a3
      lastState:
        terminated:
          containerID: docker://513e0cf147629d6c430cdb313c7888ca692f42da0859dfa125b22c9e50ce451f
          exitCode: 255
          finishedAt: "2024-08-11T12:57:38Z"
          reason: Error
          startedAt: "2024-08-11T02:15:57Z"
      name: kube-apiserver
      ready: true
      restartCount: 3
      started: true
      state:
        running:
          startedAt: "2024-08-11T12:57:45Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Running
    podIP: 192.168.49.2
    podIPs:
    - ip: 192.168.49.2
    qosClass: Burstable
    startTime: "2024-08-11T12:57:45Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/config.hash: 7fd44e8d11c3e0ffe6b1825e2a1f2270
      kubernetes.io/config.mirror: 7fd44e8d11c3e0ffe6b1825e2a1f2270
      kubernetes.io/config.seen: "2024-08-08T13:10:16.657151227Z"
      kubernetes.io/config.source: file
    creationTimestamp: "2024-08-08T13:10:16Z"
    labels:
      component: kube-controller-manager
      tier: control-plane
    name: kube-controller-manager-minikube
    namespace: kube-system
    ownerReferences:
    - apiVersion: v1
      controller: true
      kind: Node
      name: minikube
      uid: f9fe5e0a-ec7a-4ec2-90f9-a25cc3fdc836
    resourceVersion: "25905"
    uid: e1d8ce39-5385-4352-ac49-9daa94de571e
  spec:
    containers:
    - command:
      - kube-controller-manager
      - --allocate-node-cidrs=true
      - --authentication-kubeconfig=/etc/kubernetes/controller-manager.conf
      - --authorization-kubeconfig=/etc/kubernetes/controller-manager.conf
      - --bind-address=127.0.0.1
      - --client-ca-file=/var/lib/minikube/certs/ca.crt
      - --cluster-cidr=10.244.0.0/16
      - --cluster-name=mk
      - --cluster-signing-cert-file=/var/lib/minikube/certs/ca.crt
      - --cluster-signing-key-file=/var/lib/minikube/certs/ca.key
      - --controllers=*,bootstrapsigner,tokencleaner
      - --kubeconfig=/etc/kubernetes/controller-manager.conf
      - --leader-elect=false
      - --requestheader-client-ca-file=/var/lib/minikube/certs/front-proxy-ca.crt
      - --root-ca-file=/var/lib/minikube/certs/ca.crt
      - --service-account-private-key-file=/var/lib/minikube/certs/sa.key
      - --service-cluster-ip-range=10.96.0.0/12
      - --use-service-account-credentials=true
      image: registry.k8s.io/kube-controller-manager:v1.30.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 8
        httpGet:
          host: 127.0.0.1
          path: /healthz
          port: 10257
          scheme: HTTPS
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      name: kube-controller-manager
      resources:
        requests:
          cpu: 200m
      startupProbe:
        failureThreshold: 24
        httpGet:
          host: 127.0.0.1
          path: /healthz
          port: 10257
          scheme: HTTPS
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/ssl/certs
        name: ca-certs
        readOnly: true
      - mountPath: /etc/ca-certificates
        name: etc-ca-certificates
        readOnly: true
      - mountPath: /usr/libexec/kubernetes/kubelet-plugins/volume/exec
        name: flexvolume-dir
      - mountPath: /var/lib/minikube/certs
        name: k8s-certs
        readOnly: true
      - mountPath: /etc/kubernetes/controller-manager.conf
        name: kubeconfig
        readOnly: true
      - mountPath: /usr/local/share/ca-certificates
        name: usr-local-share-ca-certificates
        readOnly: true
      - mountPath: /usr/share/ca-certificates
        name: usr-share-ca-certificates
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: minikube
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      seccompProfile:
        type: RuntimeDefault
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    volumes:
    - hostPath:
        path: /etc/ssl/certs
        type: DirectoryOrCreate
      name: ca-certs
    - hostPath:
        path: /etc/ca-certificates
        type: DirectoryOrCreate
      name: etc-ca-certificates
    - hostPath:
        path: /usr/libexec/kubernetes/kubelet-plugins/volume/exec
        type: DirectoryOrCreate
      name: flexvolume-dir
    - hostPath:
        path: /var/lib/minikube/certs
        type: DirectoryOrCreate
      name: k8s-certs
    - hostPath:
        path: /etc/kubernetes/controller-manager.conf
        type: FileOrCreate
      name: kubeconfig
    - hostPath:
        path: /usr/local/share/ca-certificates
        type: DirectoryOrCreate
      name: usr-local-share-ca-certificates
    - hostPath:
        path: /usr/share/ca-certificates
        type: DirectoryOrCreate
      name: usr-share-ca-certificates
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:46Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:45Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:56Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:56Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:45Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://057b38f2251c1374010cff55894c62f98c197c0c455e2ce4f4865fff354b7860
      image: registry.k8s.io/kube-controller-manager:v1.30.0
      imageID: docker-pullable://registry.k8s.io/kube-controller-manager@sha256:5f52f00f17d5784b5ca004dffca59710fa1a9eec8d54cebdf9433a1d134150fe
      lastState:
        terminated:
          containerID: docker://323e4e1c9a0943a0c161aa395ca2354ab6e984c734397318e897a35c484eef74
          exitCode: 255
          finishedAt: "2024-08-11T12:57:38Z"
          reason: Error
          startedAt: "2024-08-11T02:15:57Z"
      name: kube-controller-manager
      ready: true
      restartCount: 3
      started: true
      state:
        running:
          startedAt: "2024-08-11T12:57:45Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Running
    podIP: 192.168.49.2
    podIPs:
    - ip: 192.168.49.2
    qosClass: Burstable
    startTime: "2024-08-11T12:57:45Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-08-08T13:10:30Z"
    generateName: kube-proxy-
    labels:
      controller-revision-hash: 79cf874c65
      k8s-app: kube-proxy
      pod-template-generation: "1"
    name: kube-proxy-xfhsx
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: kube-proxy
      uid: 65e3aa45-28c8-44a5-9a3e-8cd3a69fefbe
    resourceVersion: "25863"
    uid: f9f5e8e8-cc2f-496d-9288-6c11d9aac4c2
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - minikube
    containers:
    - command:
      - /usr/local/bin/kube-proxy
      - --config=/var/lib/kube-proxy/config.conf
      - --hostname-override=$(NODE_NAME)
      env:
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: registry.k8s.io/kube-proxy:v1.30.0
      imagePullPolicy: IfNotPresent
      name: kube-proxy
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/kube-proxy
        name: kube-proxy
      - mountPath: /run/xtables.lock
        name: xtables-lock
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-g4mz2
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: minikube
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: kube-proxy
    serviceAccountName: kube-proxy
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: kube-proxy
      name: kube-proxy
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: xtables-lock
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
    - name: kube-api-access-g4mz2
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:49Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-08-08T13:10:30Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:49Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:49Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-08-08T13:10:30Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://1bc0b9fe467cb202c8498fb4bab1148590384cefe6b8a28749eb64b2d7f9c4c6
      image: registry.k8s.io/kube-proxy:v1.30.0
      imageID: docker-pullable://registry.k8s.io/kube-proxy@sha256:ec532ff47eaf39822387e51ec73f1f2502eb74658c6303319db88d2c380d0210
      lastState:
        terminated:
          containerID: docker://4e7d541412a7253d1938dc58d33609287c6fdb073f7aa5893cb9696c70c420e9
          exitCode: 255
          finishedAt: "2024-08-11T12:57:38Z"
          reason: Error
          startedAt: "2024-08-11T02:16:02Z"
      name: kube-proxy
      ready: true
      restartCount: 3
      started: true
      state:
        running:
          startedAt: "2024-08-11T12:57:48Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Running
    podIP: 192.168.49.2
    podIPs:
    - ip: 192.168.49.2
    qosClass: BestEffort
    startTime: "2024-08-08T13:10:30Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/config.hash: f9c8e1d0d74b1727abdb4b4a31d3a7c1
      kubernetes.io/config.mirror: f9c8e1d0d74b1727abdb4b4a31d3a7c1
      kubernetes.io/config.seen: "2024-08-08T13:10:16.657152161Z"
      kubernetes.io/config.source: file
    creationTimestamp: "2024-08-08T13:10:16Z"
    labels:
      component: kube-scheduler
      tier: control-plane
    name: kube-scheduler-minikube
    namespace: kube-system
    ownerReferences:
    - apiVersion: v1
      controller: true
      kind: Node
      name: minikube
      uid: f9fe5e0a-ec7a-4ec2-90f9-a25cc3fdc836
    resourceVersion: "25914"
    uid: 83a0323f-7f11-4cac-807e-6958b5c05e39
  spec:
    containers:
    - command:
      - kube-scheduler
      - --authentication-kubeconfig=/etc/kubernetes/scheduler.conf
      - --authorization-kubeconfig=/etc/kubernetes/scheduler.conf
      - --bind-address=127.0.0.1
      - --kubeconfig=/etc/kubernetes/scheduler.conf
      - --leader-elect=false
      image: registry.k8s.io/kube-scheduler:v1.30.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 8
        httpGet:
          host: 127.0.0.1
          path: /healthz
          port: 10259
          scheme: HTTPS
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      name: kube-scheduler
      resources:
        requests:
          cpu: 100m
      startupProbe:
        failureThreshold: 24
        httpGet:
          host: 127.0.0.1
          path: /healthz
          port: 10259
          scheme: HTTPS
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/kubernetes/scheduler.conf
        name: kubeconfig
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: minikube
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      seccompProfile:
        type: RuntimeDefault
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    volumes:
    - hostPath:
        path: /etc/kubernetes/scheduler.conf
        type: FileOrCreate
      name: kubeconfig
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:46Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:45Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:57Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:57Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:45Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://c825912598f94347c1c20dbc809832f13d4c8c1c1aff55287c9ea9da83b10379
      image: registry.k8s.io/kube-scheduler:v1.30.0
      imageID: docker-pullable://registry.k8s.io/kube-scheduler@sha256:2353c3a1803229970fcb571cffc9b2f120372350e01c7381b4b650c4a02b9d67
      lastState:
        terminated:
          containerID: docker://342252ef8837c9048e925bd76c6bb4dd9dab6d83236f62b7b5127a101c2905ba
          exitCode: 255
          finishedAt: "2024-08-11T12:57:38Z"
          reason: Error
          startedAt: "2024-08-11T02:15:57Z"
      name: kube-scheduler
      ready: true
      restartCount: 3
      started: true
      state:
        running:
          startedAt: "2024-08-11T12:57:45Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Running
    podIP: 192.168.49.2
    podIPs:
    - ip: 192.168.49.2
    qosClass: Burstable
    startTime: "2024-08-11T12:57:45Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Pod","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","integration-test":"storage-provisioner"},"name":"storage-provisioner","namespace":"kube-system"},"spec":{"containers":[{"command":["/storage-provisioner"],"image":"gcr.io/k8s-minikube/storage-provisioner:v5","imagePullPolicy":"IfNotPresent","name":"storage-provisioner","volumeMounts":[{"mountPath":"/tmp","name":"tmp"}]}],"hostNetwork":true,"serviceAccountName":"storage-provisioner","volumes":[{"hostPath":{"path":"/tmp","type":"Directory"},"name":"tmp"}]}}
    creationTimestamp: "2024-08-08T13:10:17Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      integration-test: storage-provisioner
    name: storage-provisioner
    namespace: kube-system
    resourceVersion: "26071"
    uid: 52609c84-ebcc-44bf-a8e0-523b13123685
  spec:
    containers:
    - command:
      - /storage-provisioner
      image: gcr.io/k8s-minikube/storage-provisioner:v5
      imagePullPolicy: IfNotPresent
      name: storage-provisioner
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /tmp
        name: tmp
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-f864j
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: minikube
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: storage-provisioner
    serviceAccountName: storage-provisioner
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - hostPath:
        path: /tmp
        type: Directory
      name: tmp
    - name: kube-api-access-f864j
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:49Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-08-08T13:10:30Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:58:35Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:58:35Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-08-08T13:10:30Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://2bf5b6ccaaabca1947146fcf946159df3063d20933ac411a5600b72cf7ee7836
      image: gcr.io/k8s-minikube/storage-provisioner:v5
      imageID: docker-pullable://gcr.io/k8s-minikube/storage-provisioner@sha256:18eb69d1418e854ad5a19e399310e52808a8321e4c441c1dddad8977a0d7a944
      lastState:
        terminated:
          containerID: docker://21823023a80cb50fcc1325ef5931ef9533653925aad054441c5845bef6de61e9
          exitCode: 1
          finishedAt: "2024-08-11T12:58:19Z"
          reason: Error
          startedAt: "2024-08-11T12:57:48Z"
      name: storage-provisioner
      ready: true
      restartCount: 6
      started: true
      state:
        running:
          startedAt: "2024-08-11T12:58:34Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Running
    podIP: 192.168.49.2
    podIPs:
    - ip: 192.168.49.2
    qosClass: BestEffort
    startTime: "2024-08-08T13:10:30Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/default-container: alertmanager
    creationTimestamp: "2024-08-08T17:00:01Z"
    generateName: alertmanager-prometheus-kube-prometheus-alertmanager-
    labels:
      alertmanager: prometheus-kube-prometheus-alertmanager
      app.kubernetes.io/instance: prometheus-kube-prometheus-alertmanager
      app.kubernetes.io/managed-by: prometheus-operator
      app.kubernetes.io/name: alertmanager
      app.kubernetes.io/version: 0.27.0
      apps.kubernetes.io/pod-index: "0"
      controller-revision-hash: alertmanager-prometheus-kube-prometheus-alertmanager-7cbc9fffbc
      statefulset.kubernetes.io/pod-name: alertmanager-prometheus-kube-prometheus-alertmanager-0
    name: alertmanager-prometheus-kube-prometheus-alertmanager-0
    namespace: monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: StatefulSet
      name: alertmanager-prometheus-kube-prometheus-alertmanager
      uid: feb21235-defb-404e-8d42-576aa68143a4
    resourceVersion: "25895"
    uid: 813974e7-386a-4b0f-b509-89ff4072d71e
  spec:
    automountServiceAccountToken: true
    containers:
    - args:
      - --config.file=/etc/alertmanager/config_out/alertmanager.env.yaml
      - --storage.path=/alertmanager
      - --data.retention=120h
      - --cluster.listen-address=
      - --web.listen-address=:9093
      - --web.external-url=http://prometheus-kube-prometheus-alertmanager.monitoring:9093
      - --web.route-prefix=/
      - --cluster.label=monitoring/prometheus-kube-prometheus-alertmanager
      - --cluster.peer=alertmanager-prometheus-kube-prometheus-alertmanager-0.alertmanager-operated:9094
      - --cluster.reconnect-timeout=5m
      - --web.config.file=/etc/alertmanager/web_config/web-config.yaml
      env:
      - name: POD_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      image: quay.io/prometheus/alertmanager:v0.27.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 10
        httpGet:
          path: /-/healthy
          port: http-web
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 3
      name: alertmanager
      ports:
      - containerPort: 9093
        name: http-web
        protocol: TCP
      - containerPort: 9094
        name: mesh-tcp
        protocol: TCP
      - containerPort: 9094
        name: mesh-udp
        protocol: UDP
      readinessProbe:
        failureThreshold: 10
        httpGet:
          path: /-/ready
          port: http-web
          scheme: HTTP
        initialDelaySeconds: 3
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 3
      resources:
        requests:
          memory: 200Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/alertmanager/config
        name: config-volume
      - mountPath: /etc/alertmanager/config_out
        name: config-out
        readOnly: true
      - mountPath: /etc/alertmanager/certs
        name: tls-assets
        readOnly: true
      - mountPath: /alertmanager
        name: alertmanager-prometheus-kube-prometheus-alertmanager-db
      - mountPath: /etc/alertmanager/web_config/web-config.yaml
        name: web-config
        readOnly: true
        subPath: web-config.yaml
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-xt94n
        readOnly: true
    - args:
      - --listen-address=:8080
      - --reload-url=http://127.0.0.1:9093/-/reload
      - --config-file=/etc/alertmanager/config/alertmanager.yaml.gz
      - --config-envsubst-file=/etc/alertmanager/config_out/alertmanager.env.yaml
      - --watched-dir=/etc/alertmanager/config
      command:
      - /bin/prometheus-config-reloader
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: SHARD
        value: "-1"
      image: quay.io/prometheus-operator/prometheus-config-reloader:v0.75.2
      imagePullPolicy: IfNotPresent
      name: config-reloader
      ports:
      - containerPort: 8080
        name: reloader-web
        protocol: TCP
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/alertmanager/config
        name: config-volume
        readOnly: true
      - mountPath: /etc/alertmanager/config_out
        name: config-out
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-xt94n
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostname: alertmanager-prometheus-kube-prometheus-alertmanager-0
    initContainers:
    - args:
      - --watch-interval=0
      - --listen-address=:8081
      - --config-file=/etc/alertmanager/config/alertmanager.yaml.gz
      - --config-envsubst-file=/etc/alertmanager/config_out/alertmanager.env.yaml
      - --watched-dir=/etc/alertmanager/config
      command:
      - /bin/prometheus-config-reloader
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: SHARD
        value: "-1"
      image: quay.io/prometheus-operator/prometheus-config-reloader:v0.75.2
      imagePullPolicy: IfNotPresent
      name: init-config-reloader
      ports:
      - containerPort: 8081
        name: reloader-web
        protocol: TCP
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/alertmanager/config
        name: config-volume
        readOnly: true
      - mountPath: /etc/alertmanager/config_out
        name: config-out
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-xt94n
        readOnly: true
    nodeName: minikube
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 2000
      runAsGroup: 2000
      runAsNonRoot: true
      runAsUser: 1000
      seccompProfile:
        type: RuntimeDefault
    serviceAccount: prometheus-kube-prometheus-alertmanager
    serviceAccountName: prometheus-kube-prometheus-alertmanager
    subdomain: alertmanager-operated
    terminationGracePeriodSeconds: 120
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: config-volume
      secret:
        defaultMode: 420
        secretName: alertmanager-prometheus-kube-prometheus-alertmanager-generated
    - name: tls-assets
      projected:
        defaultMode: 420
        sources:
        - secret:
            name: alertmanager-prometheus-kube-prometheus-alertmanager-tls-assets-0
    - emptyDir:
        medium: Memory
      name: config-out
    - name: web-config
      secret:
        defaultMode: 420
        secretName: alertmanager-prometheus-kube-prometheus-alertmanager-web-config
    - emptyDir: {}
      name: alertmanager-prometheus-kube-prometheus-alertmanager-db
    - name: kube-api-access-xt94n
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:49Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-08-08T17:00:02Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:54Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:54Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-08-08T17:00:01Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://db001c3c573b908c156032f4be804bd75f53c4e4e4d772ce87f1b2d35ba07204
      image: quay.io/prometheus/alertmanager:v0.27.0
      imageID: docker-pullable://quay.io/prometheus/alertmanager@sha256:e13b6ed5cb929eeaee733479dce55e10eb3bc2e9c4586c705a4e8da41e5eacf5
      lastState:
        terminated:
          containerID: docker://a85740349944672be741fc1b03bd0c7fc757e732a2aecb15f6c9756dd4689a19
          exitCode: 255
          finishedAt: "2024-08-11T12:57:38Z"
          message: |
            ts=2024-08-11T02:16:03.166Z caller=main.go:181 level=info msg="Starting Alertmanager" version="(version=0.27.0, branch=HEAD, revision=0aa3c2aad14cff039931923ab16b26b7481783b5)"
            ts=2024-08-11T02:16:03.166Z caller=main.go:182 level=info build_context="(go=go1.21.7, platform=linux/amd64, user=root@22cd11f671e9, date=20240228-11:51:20, tags=netgo)"
            ts=2024-08-11T02:16:03.192Z caller=coordinator.go:113 level=info component=configuration msg="Loading configuration file" file=/etc/alertmanager/config_out/alertmanager.env.yaml
            ts=2024-08-11T02:16:03.194Z caller=coordinator.go:126 level=info component=configuration msg="Completed loading of configuration file" file=/etc/alertmanager/config_out/alertmanager.env.yaml
            ts=2024-08-11T02:16:03.199Z caller=tls_config.go:313 level=info msg="Listening on" address=[::]:9093
            ts=2024-08-11T02:16:03.199Z caller=tls_config.go:352 level=info msg="TLS is disabled." http2=false address=[::]:9093
            ts=2024-08-11T02:16:03.202Z caller=coordinator.go:113 level=info component=configuration msg="Loading configuration file" file=/etc/alertmanager/config_out/alertmanager.env.yaml
            ts=2024-08-11T02:16:03.202Z caller=coordinator.go:126 level=info component=configuration msg="Completed loading of configuration file" file=/etc/alertmanager/config_out/alertmanager.env.yaml
          reason: Error
          startedAt: "2024-08-11T02:16:03Z"
      name: alertmanager
      ready: true
      restartCount: 3
      started: true
      state:
        running:
          startedAt: "2024-08-11T12:57:49Z"
    - containerID: docker://6bd622a4513efea097f4a0c1895cbd1ccea6ccb279dd7adafdfd12db60fd7e79
      image: quay.io/prometheus-operator/prometheus-config-reloader:v0.75.2
      imageID: docker-pullable://quay.io/prometheus-operator/prometheus-config-reloader@sha256:a35f3524603260d799e34200a7499cad80a5463cf9a6628a20b960f9655cf043
      lastState:
        terminated:
          containerID: docker://a366423006a00cd6c5bb97dcf8d1a85c0be08fa8af648522b16670cfae10d94e
          exitCode: 255
          finishedAt: "2024-08-11T12:57:38Z"
          message: |
            level=info ts=2024-08-11T02:16:03.197525619Z caller=main.go:142 msg="Starting prometheus-config-reloader" version="(version=0.75.2, branch=refs/tags/v0.75.2, revision=35b0f457d8f705f1ac8282b4e22caa68a19c6c43)"
            level=info ts=2024-08-11T02:16:03.197568403Z caller=main.go:143 build_context="(go=go1.22.5, platform=linux/amd64, user=Action-Run-ID-10070178014, date=20240724-04:04:09, tags=unknown)"
            level=info ts=2024-08-11T02:16:03.197734814Z caller=cpu.go:28 msg="Leaving GOMAXPROCS=12: CPU quota undefined"
            level=info ts=2024-08-11T02:16:03.198028466Z caller=reloader.go:270 msg="reloading via HTTP"
            level=info ts=2024-08-11T02:16:03.198031605Z caller=main.go:200 msg="Starting web server for metrics" listen=:8080
            level=info ts=2024-08-11T02:16:03.201100849Z caller=tls_config.go:313 msg="Listening on" address=[::]:8080
            level=info ts=2024-08-11T02:16:03.201119389Z caller=tls_config.go:316 msg="TLS is disabled." http2=false address=[::]:8080
            level=info ts=2024-08-11T02:16:03.204130578Z caller=reloader.go:536 msg="Reload triggered" cfg_in=/etc/alertmanager/config/alertmanager.yaml.gz cfg_out=/etc/alertmanager/config_out/alertmanager.env.yaml cfg_dirs= watched_dirs=/etc/alertmanager/config
            level=info ts=2024-08-11T02:16:03.204183426Z caller=reloader.go:318 msg="started watching config file and directories for changes" cfg=/etc/alertmanager/config/alertmanager.yaml.gz cfgDirs= out=/etc/alertmanager/config_out/alertmanager.env.yaml dirs=/etc/alertmanager/config
          reason: Error
          startedAt: "2024-08-11T02:16:03Z"
      name: config-reloader
      ready: true
      restartCount: 3
      started: true
      state:
        running:
          startedAt: "2024-08-11T12:57:49Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    initContainerStatuses:
    - containerID: docker://f0f6b919e818cb6ad1f1c88490bc30789ad196c8cb58444fcdf38781d1f04726
      image: quay.io/prometheus-operator/prometheus-config-reloader:v0.75.2
      imageID: docker-pullable://quay.io/prometheus-operator/prometheus-config-reloader@sha256:a35f3524603260d799e34200a7499cad80a5463cf9a6628a20b960f9655cf043
      lastState: {}
      name: init-config-reloader
      ready: true
      restartCount: 3
      started: false
      state:
        terminated:
          containerID: docker://f0f6b919e818cb6ad1f1c88490bc30789ad196c8cb58444fcdf38781d1f04726
          exitCode: 0
          finishedAt: "2024-08-11T12:57:49Z"
          reason: Completed
          startedAt: "2024-08-11T12:57:49Z"
    phase: Running
    podIP: 10.244.0.140
    podIPs:
    - ip: 10.244.0.140
    qosClass: Burstable
    startTime: "2024-08-08T17:00:01Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      checksum/config: 0e9cbd0ea8e24e32f7dfca5bab17a2ba05652642f0a09a4882833ae88e4cc4a3
      checksum/sc-dashboard-provider-config: e70bf6a851099d385178a76de9757bb0bef8299da6d8443602590e44f05fdf24
      checksum/secret: 032056e9c62bbe9d1daa41ee49cd3d9524c076f51ca4c65adadf4ef08ef28712
      kubectl.kubernetes.io/default-container: grafana
    creationTimestamp: "2024-08-08T17:00:00Z"
    generateName: prometheus-grafana-648c7ff88d-
    labels:
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/name: grafana
      pod-template-hash: 648c7ff88d
    name: prometheus-grafana-648c7ff88d-swq8j
    namespace: monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: prometheus-grafana-648c7ff88d
      uid: 6a357f7e-1f3d-441a-afd3-51349063d3f9
    resourceVersion: "25917"
    uid: fd6a8a95-c718-4cc9-bb6e-136fa4fd6363
  spec:
    automountServiceAccountToken: true
    containers:
    - env:
      - name: METHOD
        value: WATCH
      - name: LABEL
        value: grafana_dashboard
      - name: LABEL_VALUE
        value: "1"
      - name: FOLDER
        value: /tmp/dashboards
      - name: RESOURCE
        value: both
      - name: NAMESPACE
        value: ALL
      - name: REQ_USERNAME
        valueFrom:
          secretKeyRef:
            key: admin-user
            name: prometheus-grafana
      - name: REQ_PASSWORD
        valueFrom:
          secretKeyRef:
            key: admin-password
            name: prometheus-grafana
      - name: REQ_URL
        value: http://localhost:3000/api/admin/provisioning/dashboards/reload
      - name: REQ_METHOD
        value: POST
      image: quay.io/kiwigrid/k8s-sidecar:1.27.4
      imagePullPolicy: IfNotPresent
      name: grafana-sc-dashboard
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /tmp/dashboards
        name: sc-dashboard-volume
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-hctsj
        readOnly: true
    - env:
      - name: METHOD
        value: WATCH
      - name: LABEL
        value: grafana_datasource
      - name: LABEL_VALUE
        value: "1"
      - name: FOLDER
        value: /etc/grafana/provisioning/datasources
      - name: RESOURCE
        value: both
      - name: REQ_USERNAME
        valueFrom:
          secretKeyRef:
            key: admin-user
            name: prometheus-grafana
      - name: REQ_PASSWORD
        valueFrom:
          secretKeyRef:
            key: admin-password
            name: prometheus-grafana
      - name: REQ_URL
        value: http://localhost:3000/api/admin/provisioning/datasources/reload
      - name: REQ_METHOD
        value: POST
      image: quay.io/kiwigrid/k8s-sidecar:1.27.4
      imagePullPolicy: IfNotPresent
      name: grafana-sc-datasources
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/grafana/provisioning/datasources
        name: sc-datasources-volume
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-hctsj
        readOnly: true
    - env:
      - name: POD_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      - name: GF_SECURITY_ADMIN_USER
        valueFrom:
          secretKeyRef:
            key: admin-user
            name: prometheus-grafana
      - name: GF_SECURITY_ADMIN_PASSWORD
        valueFrom:
          secretKeyRef:
            key: admin-password
            name: prometheus-grafana
      - name: GF_PATHS_DATA
        value: /var/lib/grafana/
      - name: GF_PATHS_LOGS
        value: /var/log/grafana
      - name: GF_PATHS_PLUGINS
        value: /var/lib/grafana/plugins
      - name: GF_PATHS_PROVISIONING
        value: /etc/grafana/provisioning
      image: docker.io/grafana/grafana:11.1.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 10
        httpGet:
          path: /api/health
          port: 3000
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 30
      name: grafana
      ports:
      - containerPort: 3000
        name: grafana
        protocol: TCP
      - containerPort: 9094
        name: gossip-tcp
        protocol: TCP
      - containerPort: 9094
        name: gossip-udp
        protocol: UDP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /api/health
          port: 3000
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/grafana/grafana.ini
        name: config
        subPath: grafana.ini
      - mountPath: /var/lib/grafana
        name: storage
      - mountPath: /tmp/dashboards
        name: sc-dashboard-volume
      - mountPath: /etc/grafana/provisioning/dashboards/sc-dashboardproviders.yaml
        name: sc-dashboard-provider
        subPath: provider.yaml
      - mountPath: /etc/grafana/provisioning/datasources
        name: sc-datasources-volume
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-hctsj
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: minikube
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 472
      runAsGroup: 472
      runAsNonRoot: true
      runAsUser: 472
    serviceAccount: prometheus-grafana
    serviceAccountName: prometheus-grafana
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        name: prometheus-grafana
      name: config
    - emptyDir: {}
      name: storage
    - emptyDir: {}
      name: sc-dashboard-volume
    - configMap:
        defaultMode: 420
        name: prometheus-grafana-config-dashboards
      name: sc-dashboard-provider
    - emptyDir: {}
      name: sc-datasources-volume
    - name: kube-api-access-hctsj
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:49Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-08-08T17:00:00Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:57Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:57Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-08-08T17:00:00Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://66d881cbf6151a59fbd7a4fe41a726d4b9c3b6fd41189b09b1597bf112c9b625
      image: grafana/grafana:11.1.0
      imageID: docker-pullable://grafana/grafana@sha256:079600c9517b678c10cda6006b4487d3174512fd4c6cface37df7822756ed7a5
      lastState:
        terminated:
          containerID: docker://2ad932d6611eb7a18008c2f438c886475484e93b174f6d5cb4c6ae3da6de9dc5
          exitCode: 255
          finishedAt: "2024-08-11T12:57:38Z"
          reason: Error
          startedAt: "2024-08-11T02:16:02Z"
      name: grafana
      ready: true
      restartCount: 3
      started: true
      state:
        running:
          startedAt: "2024-08-11T12:57:49Z"
    - containerID: docker://fde20d16617a6b8d72916ace857160f3c8bd2299d67029e45a711f26041337a7
      image: quay.io/kiwigrid/k8s-sidecar:1.27.4
      imageID: docker-pullable://quay.io/kiwigrid/k8s-sidecar@sha256:f6ed71d0f9f1175df8c4b8c674b339a74785384d25fdad21b3c3dc0554109286
      lastState:
        terminated:
          containerID: docker://8dd5590136501d167d5404ee59812933643388aebe3727ff2963fc262633d95e
          exitCode: 255
          finishedAt: "2024-08-11T12:57:38Z"
          reason: Error
          startedAt: "2024-08-11T02:16:02Z"
      name: grafana-sc-dashboard
      ready: true
      restartCount: 3
      started: true
      state:
        running:
          startedAt: "2024-08-11T12:57:49Z"
    - containerID: docker://3b4b4440fcddc38b82b2ef298099de93ecdba75e682a8e47a9af5205aa62daa0
      image: quay.io/kiwigrid/k8s-sidecar:1.27.4
      imageID: docker-pullable://quay.io/kiwigrid/k8s-sidecar@sha256:f6ed71d0f9f1175df8c4b8c674b339a74785384d25fdad21b3c3dc0554109286
      lastState:
        terminated:
          containerID: docker://9c198cad8c09e7c8c3086fee7b0ff06dc53d107f9244f3b72a7d342e9eac2b5b
          exitCode: 255
          finishedAt: "2024-08-11T12:57:38Z"
          reason: Error
          startedAt: "2024-08-11T02:16:02Z"
      name: grafana-sc-datasources
      ready: true
      restartCount: 3
      started: true
      state:
        running:
          startedAt: "2024-08-11T12:57:49Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Running
    podIP: 10.244.0.133
    podIPs:
    - ip: 10.244.0.133
    qosClass: BestEffort
    startTime: "2024-08-08T17:00:00Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-08-08T17:00:00Z"
    generateName: prometheus-kube-prometheus-operator-597f45494f-
    labels:
      app: kube-prometheus-stack-operator
      app.kubernetes.io/component: prometheus-operator
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: kube-prometheus-stack-prometheus-operator
      app.kubernetes.io/part-of: kube-prometheus-stack
      app.kubernetes.io/version: 61.7.2
      chart: kube-prometheus-stack-61.7.2
      heritage: Helm
      pod-template-hash: 597f45494f
      release: prometheus
    name: prometheus-kube-prometheus-operator-597f45494f-zlscx
    namespace: monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: prometheus-kube-prometheus-operator-597f45494f
      uid: 1e4ec55a-0028-47f5-9ace-1c6cf887ece5
    resourceVersion: "25995"
    uid: f1c9d3b3-e999-4480-a0e3-a0f47e2a41ef
  spec:
    automountServiceAccountToken: true
    containers:
    - args:
      - --kubelet-service=kube-system/prometheus-kube-prometheus-kubelet
      - --localhost=127.0.0.1
      - --prometheus-config-reloader=quay.io/prometheus-operator/prometheus-config-reloader:v0.75.2
      - --config-reloader-cpu-request=0
      - --config-reloader-cpu-limit=0
      - --config-reloader-memory-request=0
      - --config-reloader-memory-limit=0
      - --thanos-default-base-image=quay.io/thanos/thanos:v0.36.0
      - --secret-field-selector=type!=kubernetes.io/dockercfg,type!=kubernetes.io/service-account-token,type!=helm.sh/release.v1
      - --web.enable-tls=true
      - --web.cert-file=/cert/cert
      - --web.key-file=/cert/key
      - --web.listen-address=:10250
      - --web.tls-min-version=VersionTLS13
      env:
      - name: GOGC
        value: "30"
      image: quay.io/prometheus-operator/prometheus-operator:v0.75.2
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: https
          scheme: HTTPS
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: kube-prometheus-stack
      ports:
      - containerPort: 10250
        name: https
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: https
          scheme: HTTPS
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /cert
        name: tls-secret
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-8fpch
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: minikube
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 65534
      runAsGroup: 65534
      runAsNonRoot: true
      runAsUser: 65534
      seccompProfile:
        type: RuntimeDefault
    serviceAccount: prometheus-kube-prometheus-operator
    serviceAccountName: prometheus-kube-prometheus-operator
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: tls-secret
      secret:
        defaultMode: 420
        secretName: prometheus-kube-prometheus-admission
    - name: kube-api-access-8fpch
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:49Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-08-08T17:00:00Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:58:12Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:58:12Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-08-08T17:00:00Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://0b41b7f10d344d6d29f2e18a48f854a56d6f3a8225b3814ccfe5437d31f7a6c1
      image: quay.io/prometheus-operator/prometheus-operator:v0.75.2
      imageID: docker-pullable://quay.io/prometheus-operator/prometheus-operator@sha256:ed13e3f05d0926342e78db63a17b7fd3d608e5e00e6d93f33594d037e89394f6
      lastState:
        terminated:
          containerID: docker://66ecfaeffc7f46bd8b72ae7e1143e093107ee29a7a6946cf5e1f8ca8dc2b846f
          exitCode: 2
          finishedAt: "2024-08-11T12:58:11Z"
          reason: Error
          startedAt: "2024-08-11T12:57:49Z"
      name: kube-prometheus-stack
      ready: true
      restartCount: 5
      started: true
      state:
        running:
          startedAt: "2024-08-11T12:58:11Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Running
    podIP: 10.244.0.134
    podIPs:
    - ip: 10.244.0.134
    qosClass: BestEffort
    startTime: "2024-08-08T17:00:00Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-08-08T17:00:00Z"
    generateName: prometheus-kube-state-metrics-688d66b5b8-
    labels:
      app.kubernetes.io/component: metrics
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: kube-state-metrics
      app.kubernetes.io/part-of: kube-state-metrics
      app.kubernetes.io/version: 2.13.0
      helm.sh/chart: kube-state-metrics-5.25.1
      pod-template-hash: 688d66b5b8
      release: prometheus
    name: prometheus-kube-state-metrics-688d66b5b8-f2bsm
    namespace: monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: prometheus-kube-state-metrics-688d66b5b8
      uid: f4b90eeb-0bc8-4476-90be-f352e1f0328f
    resourceVersion: "26047"
    uid: 6d11f15d-abd0-4e6e-93a0-93c997bb9930
  spec:
    automountServiceAccountToken: true
    containers:
    - args:
      - --port=8080
      - --resources=certificatesigningrequests,configmaps,cronjobs,daemonsets,deployments,endpoints,horizontalpodautoscalers,ingresses,jobs,leases,limitranges,mutatingwebhookconfigurations,namespaces,networkpolicies,nodes,persistentvolumeclaims,persistentvolumes,poddisruptionbudgets,pods,replicasets,replicationcontrollers,resourcequotas,secrets,services,statefulsets,storageclasses,validatingwebhookconfigurations,volumeattachments
      image: registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.13.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /livez
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 5
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: kube-state-metrics
      ports:
      - containerPort: 8080
        name: http
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /readyz
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 5
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-zg69f
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: minikube
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 65534
      runAsGroup: 65534
      runAsNonRoot: true
      runAsUser: 65534
      seccompProfile:
        type: RuntimeDefault
    serviceAccount: prometheus-kube-state-metrics
    serviceAccountName: prometheus-kube-state-metrics
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-zg69f
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:49Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-08-08T17:00:00Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:58:29Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:58:29Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-08-08T17:00:00Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://87bfdccf6f664adcd02ffe6abc83ed569fca815899713137b3172740f105201b
      image: registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.13.0
      imageID: docker-pullable://registry.k8s.io/kube-state-metrics/kube-state-metrics@sha256:639a1e2da549210adddc0391ff91e270e83f7873014aec53258462812f741e6f
      lastState:
        terminated:
          containerID: docker://aed1793dc9f0a0f9107ab56086eed9fe6dea6f09daa65d70b4cfeaeb9b7fbdc6
          exitCode: 2
          finishedAt: "2024-08-11T12:58:16Z"
          reason: Error
          startedAt: "2024-08-11T12:57:48Z"
      name: kube-state-metrics
      ready: true
      restartCount: 5
      started: true
      state:
        running:
          startedAt: "2024-08-11T12:58:16Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Running
    podIP: 10.244.0.132
    podIPs:
    - ip: 10.244.0.132
    qosClass: BestEffort
    startTime: "2024-08-08T17:00:00Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/default-container: prometheus
    creationTimestamp: "2024-08-08T17:00:01Z"
    generateName: prometheus-prometheus-kube-prometheus-prometheus-
    labels:
      app.kubernetes.io/instance: prometheus-kube-prometheus-prometheus
      app.kubernetes.io/managed-by: prometheus-operator
      app.kubernetes.io/name: prometheus
      app.kubernetes.io/version: 2.53.1
      apps.kubernetes.io/pod-index: "0"
      controller-revision-hash: prometheus-prometheus-kube-prometheus-prometheus-545cdf7b5b
      operator.prometheus.io/name: prometheus-kube-prometheus-prometheus
      operator.prometheus.io/shard: "0"
      prometheus: prometheus-kube-prometheus-prometheus
      statefulset.kubernetes.io/pod-name: prometheus-prometheus-kube-prometheus-prometheus-0
    name: prometheus-prometheus-kube-prometheus-prometheus-0
    namespace: monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: StatefulSet
      name: prometheus-prometheus-kube-prometheus-prometheus
      uid: 33ad9af7-127c-42f9-94c7-a0bfdbeb5d67
    resourceVersion: "25928"
    uid: b8ac867d-bd92-4544-bb9d-acdbf53e262a
  spec:
    automountServiceAccountToken: true
    containers:
    - args:
      - --web.console.templates=/etc/prometheus/consoles
      - --web.console.libraries=/etc/prometheus/console_libraries
      - --config.file=/etc/prometheus/config_out/prometheus.env.yaml
      - --web.enable-lifecycle
      - --web.external-url=http://prometheus-kube-prometheus-prometheus.monitoring:9090
      - --web.route-prefix=/
      - --storage.tsdb.retention.time=10d
      - --storage.tsdb.path=/prometheus
      - --storage.tsdb.wal-compression
      - --web.config.file=/etc/prometheus/web_config/web-config.yaml
      image: quay.io/prometheus/prometheus:v2.53.1
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 6
        httpGet:
          path: /-/healthy
          port: http-web
          scheme: HTTP
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 3
      name: prometheus
      ports:
      - containerPort: 9090
        name: http-web
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /-/ready
          port: http-web
          scheme: HTTP
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 3
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      startupProbe:
        failureThreshold: 60
        httpGet:
          path: /-/ready
          port: http-web
          scheme: HTTP
        periodSeconds: 15
        successThreshold: 1
        timeoutSeconds: 3
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/prometheus/config_out
        name: config-out
        readOnly: true
      - mountPath: /etc/prometheus/certs
        name: tls-assets
        readOnly: true
      - mountPath: /prometheus
        name: prometheus-prometheus-kube-prometheus-prometheus-db
      - mountPath: /etc/prometheus/rules/prometheus-prometheus-kube-prometheus-prometheus-rulefiles-0
        name: prometheus-prometheus-kube-prometheus-prometheus-rulefiles-0
      - mountPath: /etc/prometheus/web_config/web-config.yaml
        name: web-config
        readOnly: true
        subPath: web-config.yaml
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-rgnpr
        readOnly: true
    - args:
      - --listen-address=:8080
      - --reload-url=http://127.0.0.1:9090/-/reload
      - --config-file=/etc/prometheus/config/prometheus.yaml.gz
      - --config-envsubst-file=/etc/prometheus/config_out/prometheus.env.yaml
      - --watched-dir=/etc/prometheus/rules/prometheus-prometheus-kube-prometheus-prometheus-rulefiles-0
      command:
      - /bin/prometheus-config-reloader
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: SHARD
        value: "0"
      image: quay.io/prometheus-operator/prometheus-config-reloader:v0.75.2
      imagePullPolicy: IfNotPresent
      name: config-reloader
      ports:
      - containerPort: 8080
        name: reloader-web
        protocol: TCP
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/prometheus/config
        name: config
      - mountPath: /etc/prometheus/config_out
        name: config-out
      - mountPath: /etc/prometheus/rules/prometheus-prometheus-kube-prometheus-prometheus-rulefiles-0
        name: prometheus-prometheus-kube-prometheus-prometheus-rulefiles-0
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-rgnpr
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostname: prometheus-prometheus-kube-prometheus-prometheus-0
    initContainers:
    - args:
      - --watch-interval=0
      - --listen-address=:8081
      - --config-file=/etc/prometheus/config/prometheus.yaml.gz
      - --config-envsubst-file=/etc/prometheus/config_out/prometheus.env.yaml
      - --watched-dir=/etc/prometheus/rules/prometheus-prometheus-kube-prometheus-prometheus-rulefiles-0
      command:
      - /bin/prometheus-config-reloader
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: SHARD
        value: "0"
      image: quay.io/prometheus-operator/prometheus-config-reloader:v0.75.2
      imagePullPolicy: IfNotPresent
      name: init-config-reloader
      ports:
      - containerPort: 8081
        name: reloader-web
        protocol: TCP
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/prometheus/config
        name: config
      - mountPath: /etc/prometheus/config_out
        name: config-out
      - mountPath: /etc/prometheus/rules/prometheus-prometheus-kube-prometheus-prometheus-rulefiles-0
        name: prometheus-prometheus-kube-prometheus-prometheus-rulefiles-0
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-rgnpr
        readOnly: true
    nodeName: minikube
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 2000
      runAsGroup: 2000
      runAsNonRoot: true
      runAsUser: 1000
      seccompProfile:
        type: RuntimeDefault
    serviceAccount: prometheus-kube-prometheus-prometheus
    serviceAccountName: prometheus-kube-prometheus-prometheus
    shareProcessNamespace: false
    subdomain: prometheus-operated
    terminationGracePeriodSeconds: 600
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: config
      secret:
        defaultMode: 420
        secretName: prometheus-prometheus-kube-prometheus-prometheus
    - name: tls-assets
      projected:
        defaultMode: 420
        sources:
        - secret:
            name: prometheus-prometheus-kube-prometheus-prometheus-tls-assets-0
    - emptyDir:
        medium: Memory
      name: config-out
    - configMap:
        defaultMode: 420
        name: prometheus-prometheus-kube-prometheus-prometheus-rulefiles-0
      name: prometheus-prometheus-kube-prometheus-prometheus-rulefiles-0
    - name: web-config
      secret:
        defaultMode: 420
        secretName: prometheus-prometheus-kube-prometheus-prometheus-web-config
    - emptyDir: {}
      name: prometheus-prometheus-kube-prometheus-prometheus-db
    - name: kube-api-access-rgnpr
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:49Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-08-08T17:00:02Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:59Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:59Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-08-08T17:00:01Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://713f90ec5dad23cf8a9864b0f6b29732c364d2836d3f78c97a0f08ea95992325
      image: quay.io/prometheus-operator/prometheus-config-reloader:v0.75.2
      imageID: docker-pullable://quay.io/prometheus-operator/prometheus-config-reloader@sha256:a35f3524603260d799e34200a7499cad80a5463cf9a6628a20b960f9655cf043
      lastState:
        terminated:
          containerID: docker://af813ec3c2fd0c8d381457c2a750f554215c3e5e5559d320f5fa59890a91ed69
          exitCode: 255
          finishedAt: "2024-08-11T12:57:38Z"
          message: |
            level=info ts=2024-08-11T02:16:03.270453905Z caller=main.go:142 msg="Starting prometheus-config-reloader" version="(version=0.75.2, branch=refs/tags/v0.75.2, revision=35b0f457d8f705f1ac8282b4e22caa68a19c6c43)"
            level=info ts=2024-08-11T02:16:03.270508393Z caller=main.go:143 build_context="(go=go1.22.5, platform=linux/amd64, user=Action-Run-ID-10070178014, date=20240724-04:04:09, tags=unknown)"
            level=info ts=2024-08-11T02:16:03.270703997Z caller=cpu.go:28 msg="Leaving GOMAXPROCS=12: CPU quota undefined"
            level=info ts=2024-08-11T02:16:03.271052198Z caller=main.go:200 msg="Starting web server for metrics" listen=:8080
            level=info ts=2024-08-11T02:16:03.271073779Z caller=reloader.go:270 msg="reloading via HTTP"
            level=info ts=2024-08-11T02:16:03.27124055Z caller=tls_config.go:313 msg="Listening on" address=[::]:8080
            level=info ts=2024-08-11T02:16:03.271249039Z caller=tls_config.go:316 msg="TLS is disabled." http2=false address=[::]:8080
            level=error ts=2024-08-11T02:16:03.273780852Z caller=runutil.go:117 msg="function failed. Retrying in next tick" err="trigger reload: reload request failed: Post \"http://127.0.0.1:9090/-/reload\": dial tcp 127.0.0.1:9090: connect: connection refused"
            level=info ts=2024-08-11T02:16:08.312217412Z caller=reloader.go:536 msg="Reload triggered" cfg_in=/etc/prometheus/config/prometheus.yaml.gz cfg_out=/etc/prometheus/config_out/prometheus.env.yaml cfg_dirs= watched_dirs=/etc/prometheus/rules/prometheus-prometheus-kube-prometheus-prometheus-rulefiles-0
            level=info ts=2024-08-11T02:16:08.312265993Z caller=reloader.go:318 msg="started watching config file and directories for changes" cfg=/etc/prometheus/config/prometheus.yaml.gz cfgDirs= out=/etc/prometheus/config_out/prometheus.env.yaml dirs=/etc/prometheus/rules/prometheus-prometheus-kube-prometheus-prometheus-rulefiles-0
          reason: Error
          startedAt: "2024-08-11T02:16:03Z"
      name: config-reloader
      ready: true
      restartCount: 3
      started: true
      state:
        running:
          startedAt: "2024-08-11T12:57:49Z"
    - containerID: docker://9b03d415c861b0183689c7093be2fb85837c129961dcce7d684123e51bf97789
      image: quay.io/prometheus/prometheus:v2.53.1
      imageID: docker-pullable://quay.io/prometheus/prometheus@sha256:f20d3127bf2876f4a1df76246fca576b41ddf1125ed1c546fbd8b16ea55117e6
      lastState:
        terminated:
          containerID: docker://310db757e02251696e61eca7f73f3eb40d52165ffc0f566a2365a7a14895ce42
          exitCode: 255
          finishedAt: "2024-08-11T12:57:38Z"
          message: |
            int.go:101 level=info component=tsdb msg="Creating checkpoint" from_segment=0 to_segment=1 mint=1723154400000
            ts=2024-08-11T02:16:05.092Z caller=head.go:1317 level=info component=tsdb msg="WAL checkpoint complete" first=0 last=1 duration=146.065359ms
            ts=2024-08-11T02:16:08.274Z caller=main.go:1354 level=info msg="Loading configuration file" filename=/etc/prometheus/config_out/prometheus.env.yaml
            ts=2024-08-11T02:16:08.279Z caller=kubernetes.go:331 level=info component="discovery manager scrape" discovery=kubernetes config=serviceMonitor/monitoring/prometheus-kube-prometheus-alertmanager/0 msg="Using pod service account via in-cluster config"
            ts=2024-08-11T02:16:08.279Z caller=kubernetes.go:331 level=info component="discovery manager scrape" discovery=kubernetes config=serviceMonitor/monitoring/prometheus-kube-prometheus-kube-etcd/0 msg="Using pod service account via in-cluster config"
            ts=2024-08-11T02:16:08.279Z caller=kubernetes.go:331 level=info component="discovery manager scrape" discovery=kubernetes config=serviceMonitor/default/ingress-app-ingress-nginx-controller/0 msg="Using pod service account via in-cluster config"
            ts=2024-08-11T02:16:08.279Z caller=kubernetes.go:331 level=info component="discovery manager notify" discovery=kubernetes config=config-0 msg="Using pod service account via in-cluster config"
            ts=2024-08-11T02:16:08.311Z caller=main.go:1402 level=info msg="Completed loading of configuration file" filename=/etc/prometheus/config_out/prometheus.env.yaml totalDuration=37.527158ms db_storage=1.029s remote_storage=1.339s web_handler=332ns query_engine=827ns scrape=45.771s scrape_sd=540.212s notify=10.078s notify_sd=126.223s rules=32.149371ms tracing=5.203s
            ts=2024-08-11T02:16:16.002Z caller=compact.go:576 level=info component=tsdb msg="write block" mint=1723285909579 maxt=1723291200000 ulid=01J4ZKHPB3B2VAND91NM4FQQFV duration=31.08879ms ooo=false
            ts=2024-08-11T02:16:16.006Z caller=head.go:1355 level=info component=tsdb msg="Head GC completed" caller=truncateMemory duration=3.108309ms
          reason: Error
          startedAt: "2024-08-11T02:16:03Z"
      name: prometheus
      ready: true
      restartCount: 3
      started: true
      state:
        running:
          startedAt: "2024-08-11T12:57:49Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    initContainerStatuses:
    - containerID: docker://a026521d9f69c870be6f1b70a8012a69aaf638080b9471aac673f978bd53f024
      image: quay.io/prometheus-operator/prometheus-config-reloader:v0.75.2
      imageID: docker-pullable://quay.io/prometheus-operator/prometheus-config-reloader@sha256:a35f3524603260d799e34200a7499cad80a5463cf9a6628a20b960f9655cf043
      lastState: {}
      name: init-config-reloader
      ready: true
      restartCount: 3
      started: false
      state:
        terminated:
          containerID: docker://a026521d9f69c870be6f1b70a8012a69aaf638080b9471aac673f978bd53f024
          exitCode: 0
          finishedAt: "2024-08-11T12:57:49Z"
          reason: Completed
          startedAt: "2024-08-11T12:57:49Z"
    phase: Running
    podIP: 10.244.0.139
    podIPs:
    - ip: 10.244.0.139
    qosClass: BestEffort
    startTime: "2024-08-08T17:00:01Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cluster-autoscaler.kubernetes.io/safe-to-evict: "true"
    creationTimestamp: "2024-08-08T17:00:00Z"
    generateName: prometheus-prometheus-node-exporter-
    labels:
      app.kubernetes.io/component: metrics
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: prometheus-node-exporter
      app.kubernetes.io/part-of: prometheus-node-exporter
      app.kubernetes.io/version: 1.8.2
      controller-revision-hash: 7f4c7cc867
      helm.sh/chart: prometheus-node-exporter-4.37.3
      jobLabel: node-exporter
      pod-template-generation: "2"
      release: prometheus
    name: prometheus-prometheus-node-exporter-hxxn8
    namespace: monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: prometheus-prometheus-node-exporter
      uid: 1a27937e-2e58-492e-94ad-9314599b816f
    resourceVersion: "25898"
    uid: 64d3aa0c-9644-4342-bd6a-8971bd63d425
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - minikube
    automountServiceAccountToken: false
    containers:
    - args:
      - --path.procfs=/host/proc
      - --path.sysfs=/host/sys
      - --path.rootfs=/host/root
      - --path.udev.data=/host/root/run/udev/data
      - --web.listen-address=[$(HOST_IP)]:9100
      - --collector.filesystem.mount-points-exclude=^/(dev|proc|sys|var/lib/docker/.+|var/lib/kubelet/.+)($|/)
      - --collector.filesystem.fs-types-exclude=^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs)$
      env:
      - name: HOST_IP
        value: 0.0.0.0
      image: quay.io/prometheus/node-exporter:v1.8.2
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /
          port: 9100
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: node-exporter
      ports:
      - containerPort: 9100
        hostPort: 9100
        name: http-metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /
          port: 9100
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources: {}
      securityContext:
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host/proc
        name: proc
        readOnly: true
      - mountPath: /host/sys
        name: sys
        readOnly: true
      - mountPath: /host/root
        mountPropagation: HostToContainer
        name: root
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    hostPID: true
    nodeName: minikube
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 65534
      runAsGroup: 65534
      runAsNonRoot: true
      runAsUser: 65534
    serviceAccount: prometheus-prometheus-node-exporter
    serviceAccountName: prometheus-prometheus-node-exporter
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - hostPath:
        path: /proc
        type: ""
      name: proc
    - hostPath:
        path: /sys
        type: ""
      name: sys
    - hostPath:
        path: /
        type: ""
      name: root
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:49Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-08-08T17:00:00Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:55Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-08-11T12:57:55Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-08-08T17:00:00Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://9db6533ab0ba8a5769a9fa6119e6eff6e9c31a50b63f466fe18cc287c8dc900f
      image: quay.io/prometheus/node-exporter:v1.8.2
      imageID: docker-pullable://quay.io/prometheus/node-exporter@sha256:4032c6d5bfd752342c3e631c2f1de93ba6b86c41db6b167b9a35372c139e7706
      lastState:
        terminated:
          containerID: docker://3348c7443c3635df6521acb3a7e527fd2cc6bbde3671397e7560e41cc20558a3
          exitCode: 255
          finishedAt: "2024-08-11T12:57:38Z"
          reason: Error
          startedAt: "2024-08-11T02:16:02Z"
      name: node-exporter
      ready: true
      restartCount: 3
      started: true
      state:
        running:
          startedAt: "2024-08-11T12:57:48Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Running
    podIP: 192.168.49.2
    podIPs:
    - ip: 192.168.49.2
    qosClass: BestEffort
    startTime: "2024-08-08T17:00:00Z"
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: ingress-app
      meta.helm.sh/release-namespace: default
    creationTimestamp: "2024-08-08T17:30:13Z"
    labels:
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: ingress-app
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: ingress-nginx
      app.kubernetes.io/part-of: ingress-nginx
      app.kubernetes.io/version: 1.11.1
      helm.sh/chart: ingress-nginx-4.11.1
    name: ingress-app-ingress-nginx-controller
    namespace: default
    resourceVersion: "16977"
    uid: f0200159-6a48-47f5-a890-938d62e260a6
  spec:
    allocateLoadBalancerNodePorts: true
    clusterIP: 10.96.53.53
    clusterIPs:
    - 10.96.53.53
    externalTrafficPolicy: Cluster
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - appProtocol: http
      name: http
      nodePort: 32262
      port: 80
      protocol: TCP
      targetPort: http
    - appProtocol: https
      name: https
      nodePort: 30741
      port: 443
      protocol: TCP
      targetPort: https
    selector:
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: ingress-app
      app.kubernetes.io/name: ingress-nginx
    sessionAffinity: None
    type: LoadBalancer
  status:
    loadBalancer:
      ingress:
      - ip: 10.96.53.53
        ipMode: VIP
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: ingress-app
      meta.helm.sh/release-namespace: default
    creationTimestamp: "2024-08-08T17:30:13Z"
    labels:
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: ingress-app
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: ingress-nginx
      app.kubernetes.io/part-of: ingress-nginx
      app.kubernetes.io/version: 1.11.1
      helm.sh/chart: ingress-nginx-4.11.1
    name: ingress-app-ingress-nginx-controller-admission
    namespace: default
    resourceVersion: "16907"
    uid: c7b1ce27-4292-4ad8-9ddc-96be7c6b2ff5
  spec:
    clusterIP: 10.99.246.26
    clusterIPs:
    - 10.99.246.26
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - appProtocol: https
      name: https-webhook
      port: 443
      protocol: TCP
      targetPort: webhook
    selector:
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: ingress-app
      app.kubernetes.io/name: ingress-nginx
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: ingress-app
      meta.helm.sh/release-namespace: default
    creationTimestamp: "2024-08-08T17:30:13Z"
    labels:
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: ingress-app
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: ingress-nginx
      app.kubernetes.io/part-of: ingress-nginx
      app.kubernetes.io/version: 1.11.1
      helm.sh/chart: ingress-nginx-4.11.1
    name: ingress-app-ingress-nginx-controller-metrics
    namespace: default
    resourceVersion: "16903"
    uid: 4aff14f5-e631-48f0-acd3-8db0ea2a8a53
  spec:
    clusterIP: 10.111.123.26
    clusterIPs:
    - 10.111.123.26
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: metrics
      port: 10254
      protocol: TCP
      targetPort: metrics
    selector:
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: ingress-app
      app.kubernetes.io/name: ingress-nginx
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    creationTimestamp: "2024-08-08T13:10:16Z"
    labels:
      component: apiserver
      provider: kubernetes
    name: kubernetes
    namespace: default
    resourceVersion: "198"
    uid: 6af7f509-2de5-40af-8d6e-1b89f8ca8de8
  spec:
    clusterIP: 10.96.0.1
    clusterIPs:
    - 10.96.0.1
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: https
      port: 443
      protocol: TCP
      targetPort: 8443
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"name":"ml-api-service","namespace":"default"},"spec":{"ports":[{"port":80,"protocol":"TCP","targetPort":5000}],"selector":{"app":"ml-api"}}}
    creationTimestamp: "2024-08-11T14:40:31Z"
    name: ml-api-service
    namespace: default
    resourceVersion: "33045"
    uid: 5b9073de-9839-4886-8da1-1c5d9d0373f0
  spec:
    clusterIP: 10.101.53.44
    clusterIPs:
    - 10.101.53.44
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - port: 80
      protocol: TCP
      targetPort: 5000
    selector:
      app: ml-api
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"name":"nodeapp-service","namespace":"default"},"spec":{"externalIPs":["10.0.0.100"],"ports":[{"nodePort":32000,"port":5000,"protocol":"TCP","targetPort":4000}],"selector":{"app":"nodeapp"},"type":"LoadBalancer"}}
    creationTimestamp: "2024-08-08T13:12:37Z"
    name: nodeapp-service
    namespace: default
    resourceVersion: "12239"
    uid: e8efba18-c4f1-4b3d-ba65-0b2b6d4921b0
  spec:
    allocateLoadBalancerNodePorts: true
    clusterIP: 10.100.135.236
    clusterIPs:
    - 10.100.135.236
    externalIPs:
    - 10.0.0.100
    externalTrafficPolicy: Cluster
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - nodePort: 32000
      port: 5000
      protocol: TCP
      targetPort: 4000
    selector:
      app: nodeapp
    sessionAffinity: None
    type: LoadBalancer
  status:
    loadBalancer:
      ingress:
      - ip: 10.100.135.236
        ipMode: VIP
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"labels":{"app.kubernetes.io/component":"controller","app.kubernetes.io/instance":"ingress-nginx","app.kubernetes.io/name":"ingress-nginx"},"name":"ingress-nginx-controller","namespace":"ingress-nginx"},"spec":{"ipFamilies":["IPv4"],"ipFamilyPolicy":"SingleStack","ports":[{"appProtocol":"http","name":"http","port":80,"protocol":"TCP","targetPort":"http"},{"appProtocol":"https","name":"https","port":443,"protocol":"TCP","targetPort":"https"}],"selector":{"app.kubernetes.io/component":"controller","app.kubernetes.io/instance":"ingress-nginx","app.kubernetes.io/name":"ingress-nginx"},"type":"NodePort"}}
    creationTimestamp: "2024-08-08T16:24:08Z"
    labels:
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: ingress-nginx
      app.kubernetes.io/name: ingress-nginx
    name: ingress-nginx-controller
    namespace: ingress-nginx
    resourceVersion: "12128"
    uid: 7e498f8a-8875-4965-9db2-04928ef93842
  spec:
    clusterIP: 10.109.128.94
    clusterIPs:
    - 10.109.128.94
    externalTrafficPolicy: Cluster
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - appProtocol: http
      name: http
      nodePort: 32341
      port: 80
      protocol: TCP
      targetPort: http
    - appProtocol: https
      name: https
      nodePort: 30480
      port: 443
      protocol: TCP
      targetPort: https
    selector:
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: ingress-nginx
      app.kubernetes.io/name: ingress-nginx
    sessionAffinity: None
    type: NodePort
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"labels":{"app.kubernetes.io/component":"controller","app.kubernetes.io/instance":"ingress-nginx","app.kubernetes.io/name":"ingress-nginx"},"name":"ingress-nginx-controller-admission","namespace":"ingress-nginx"},"spec":{"ports":[{"appProtocol":"https","name":"https-webhook","port":443,"targetPort":"webhook"}],"selector":{"app.kubernetes.io/component":"controller","app.kubernetes.io/instance":"ingress-nginx","app.kubernetes.io/name":"ingress-nginx"},"type":"ClusterIP"}}
    creationTimestamp: "2024-08-08T16:24:08Z"
    labels:
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: ingress-nginx
      app.kubernetes.io/name: ingress-nginx
    name: ingress-nginx-controller-admission
    namespace: ingress-nginx
    resourceVersion: "12132"
    uid: 15c655f5-8a65-4982-be5f-faa7199f50b4
  spec:
    clusterIP: 10.99.29.120
    clusterIPs:
    - 10.99.29.120
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - appProtocol: https
      name: https-webhook
      port: 443
      protocol: TCP
      targetPort: webhook
    selector:
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: ingress-nginx
      app.kubernetes.io/name: ingress-nginx
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      prometheus.io/port: "9153"
      prometheus.io/scrape: "true"
    creationTimestamp: "2024-08-08T13:10:16Z"
    labels:
      k8s-app: kube-dns
      kubernetes.io/cluster-service: "true"
      kubernetes.io/name: CoreDNS
    name: kube-dns
    namespace: kube-system
    resourceVersion: "247"
    uid: ce861702-ed18-45ca-977b-4645f06a7088
  spec:
    clusterIP: 10.96.0.10
    clusterIPs:
    - 10.96.0.10
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: dns
      port: 53
      protocol: UDP
      targetPort: 53
    - name: dns-tcp
      port: 53
      protocol: TCP
      targetPort: 53
    - name: metrics
      port: 9153
      protocol: TCP
      targetPort: 9153
    selector:
      k8s-app: kube-dns
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2024-08-08T17:00:00Z"
    labels:
      app: kube-prometheus-stack-coredns
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/part-of: kube-prometheus-stack
      app.kubernetes.io/version: 61.7.2
      chart: kube-prometheus-stack-61.7.2
      heritage: Helm
      jobLabel: coredns
      release: prometheus
    name: prometheus-kube-prometheus-coredns
    namespace: kube-system
    resourceVersion: "14624"
    uid: ffaf821a-d166-4d84-96f2-47490ece1914
  spec:
    clusterIP: None
    clusterIPs:
    - None
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: http-metrics
      port: 9153
      protocol: TCP
      targetPort: 9153
    selector:
      k8s-app: kube-dns
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2024-08-08T17:00:00Z"
    labels:
      app: kube-prometheus-stack-kube-controller-manager
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/part-of: kube-prometheus-stack
      app.kubernetes.io/version: 61.7.2
      chart: kube-prometheus-stack-61.7.2
      heritage: Helm
      jobLabel: kube-controller-manager
      release: prometheus
    name: prometheus-kube-prometheus-kube-controller-manager
    namespace: kube-system
    resourceVersion: "14627"
    uid: eb6b42ef-aaef-47e5-addf-c8a761338d52
  spec:
    clusterIP: None
    clusterIPs:
    - None
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: http-metrics
      port: 10257
      protocol: TCP
      targetPort: 10257
    selector:
      component: kube-controller-manager
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2024-08-08T17:00:00Z"
    labels:
      app: kube-prometheus-stack-kube-etcd
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/part-of: kube-prometheus-stack
      app.kubernetes.io/version: 61.7.2
      chart: kube-prometheus-stack-61.7.2
      heritage: Helm
      jobLabel: kube-etcd
      release: prometheus
    name: prometheus-kube-prometheus-kube-etcd
    namespace: kube-system
    resourceVersion: "14630"
    uid: 8f6e858b-b72c-4f8e-9617-1605a9b858ea
  spec:
    clusterIP: None
    clusterIPs:
    - None
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: http-metrics
      port: 2381
      protocol: TCP
      targetPort: 2381
    selector:
      component: etcd
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2024-08-08T17:00:00Z"
    labels:
      app: kube-prometheus-stack-kube-proxy
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/part-of: kube-prometheus-stack
      app.kubernetes.io/version: 61.7.2
      chart: kube-prometheus-stack-61.7.2
      heritage: Helm
      jobLabel: kube-proxy
      release: prometheus
    name: prometheus-kube-prometheus-kube-proxy
    namespace: kube-system
    resourceVersion: "14633"
    uid: b3938c0e-be6c-4817-a9b4-d98b2014ea87
  spec:
    clusterIP: None
    clusterIPs:
    - None
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: http-metrics
      port: 10249
      protocol: TCP
      targetPort: 10249
    selector:
      k8s-app: kube-proxy
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2024-08-08T17:00:00Z"
    labels:
      app: kube-prometheus-stack-kube-scheduler
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/part-of: kube-prometheus-stack
      app.kubernetes.io/version: 61.7.2
      chart: kube-prometheus-stack-61.7.2
      heritage: Helm
      jobLabel: kube-scheduler
      release: prometheus
    name: prometheus-kube-prometheus-kube-scheduler
    namespace: kube-system
    resourceVersion: "14636"
    uid: b3ab2045-e14c-41ac-b502-7534a85e7409
  spec:
    clusterIP: None
    clusterIPs:
    - None
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: http-metrics
      port: 10259
      protocol: TCP
      targetPort: 10259
    selector:
      component: kube-scheduler
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    creationTimestamp: "2024-08-08T13:11:23Z"
    labels:
      app.kubernetes.io/managed-by: prometheus-operator
      app.kubernetes.io/name: kubelet
      k8s-app: kubelet
    name: prometheus-kube-prometheus-kubelet
    namespace: kube-system
    resourceVersion: "721"
    uid: cd6d3295-6ed9-47e5-afd1-7ce2610ad65b
  spec:
    clusterIP: None
    clusterIPs:
    - None
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    - IPv6
    ipFamilyPolicy: RequireDualStack
    ports:
    - name: https-metrics
      port: 10250
      protocol: TCP
      targetPort: 10250
    - name: http-metrics
      port: 10255
      protocol: TCP
      targetPort: 10255
    - name: cadvisor
      port: 4194
      protocol: TCP
      targetPort: 4194
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    creationTimestamp: "2024-08-08T17:00:01Z"
    labels:
      managed-by: prometheus-operator
      operated-alertmanager: "true"
    name: alertmanager-operated
    namespace: monitoring
    ownerReferences:
    - apiVersion: monitoring.coreos.com/v1
      kind: Alertmanager
      name: prometheus-kube-prometheus-alertmanager
      uid: 73e8987a-5d71-4ec1-995f-e6dc3bdaf7e1
    resourceVersion: "14747"
    uid: 31675531-9f55-454d-822f-3646f4910703
  spec:
    clusterIP: None
    clusterIPs:
    - None
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: http-web
      port: 9093
      protocol: TCP
      targetPort: http-web
    - name: tcp-mesh
      port: 9094
      protocol: TCP
      targetPort: 9094
    - name: udp-mesh
      port: 9094
      protocol: UDP
      targetPort: 9094
    selector:
      app.kubernetes.io/name: alertmanager
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: ingress-monitor-nginx
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2024-08-08T16:12:34Z"
    labels:
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: ingress-monitor-nginx
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: ingress-nginx
      app.kubernetes.io/part-of: ingress-nginx
      app.kubernetes.io/version: 1.11.1
      helm.sh/chart: ingress-nginx-4.11.1
    name: ingress-monitor-nginx-ingress-nginx-controller
    namespace: monitoring
    resourceVersion: "12240"
    uid: 139a4cac-3c36-460f-a35c-45695eff2bf0
  spec:
    allocateLoadBalancerNodePorts: true
    clusterIP: 10.104.1.82
    clusterIPs:
    - 10.104.1.82
    externalTrafficPolicy: Cluster
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - appProtocol: http
      name: http
      nodePort: 32690
      port: 80
      protocol: TCP
      targetPort: http
    - appProtocol: https
      name: https
      nodePort: 31023
      port: 443
      protocol: TCP
      targetPort: https
    selector:
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: ingress-monitor-nginx
      app.kubernetes.io/name: ingress-nginx
    sessionAffinity: None
    type: LoadBalancer
  status:
    loadBalancer:
      ingress:
      - ip: 10.104.1.82
        ipMode: VIP
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: ingress-monitor-nginx
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2024-08-08T16:12:34Z"
    labels:
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: ingress-monitor-nginx
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: ingress-nginx
      app.kubernetes.io/part-of: ingress-nginx
      app.kubernetes.io/version: 1.11.1
      helm.sh/chart: ingress-nginx-4.11.1
    name: ingress-monitor-nginx-ingress-nginx-controller-admission
    namespace: monitoring
    resourceVersion: "11329"
    uid: 7c642b9b-ead0-4176-8079-69912e817aa8
  spec:
    clusterIP: 10.102.201.167
    clusterIPs:
    - 10.102.201.167
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - appProtocol: https
      name: https-webhook
      port: 443
      protocol: TCP
      targetPort: webhook
    selector:
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: ingress-monitor-nginx
      app.kubernetes.io/name: ingress-nginx
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: ingress-monitor-nginx
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2024-08-08T16:12:34Z"
    labels:
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: ingress-monitor-nginx
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: ingress-nginx
      app.kubernetes.io/part-of: ingress-nginx
      app.kubernetes.io/version: 1.11.1
      helm.sh/chart: ingress-nginx-4.11.1
    name: ingress-monitor-nginx-ingress-nginx-controller-metrics
    namespace: monitoring
    resourceVersion: "11326"
    uid: 6a14cd50-a457-4c2e-b887-dfc7d675b5ea
  spec:
    clusterIP: 10.102.7.157
    clusterIPs:
    - 10.102.7.157
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: metrics
      port: 10254
      protocol: TCP
      targetPort: metrics
    selector:
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: ingress-monitor-nginx
      app.kubernetes.io/name: ingress-nginx
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2024-08-08T17:00:00Z"
    labels:
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: grafana
      app.kubernetes.io/version: 11.1.0
      helm.sh/chart: grafana-8.3.8
    name: prometheus-grafana
    namespace: monitoring
    resourceVersion: "14610"
    uid: 879305b8-1854-479e-b519-e217d5f41b20
  spec:
    clusterIP: 10.102.204.57
    clusterIPs:
    - 10.102.204.57
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: http-web
      port: 80
      protocol: TCP
      targetPort: 3000
    selector:
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/name: grafana
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2024-08-08T17:00:00Z"
    labels:
      app: kube-prometheus-stack-alertmanager
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/part-of: kube-prometheus-stack
      app.kubernetes.io/version: 61.7.2
      chart: kube-prometheus-stack-61.7.2
      heritage: Helm
      release: prometheus
      self-monitor: "true"
    name: prometheus-kube-prometheus-alertmanager
    namespace: monitoring
    resourceVersion: "14621"
    uid: fed9e9d5-e0e9-498b-8c59-5c2b2eb8ec73
  spec:
    clusterIP: 10.105.101.116
    clusterIPs:
    - 10.105.101.116
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: http-web
      port: 9093
      protocol: TCP
      targetPort: 9093
    - appProtocol: http
      name: reloader-web
      port: 8080
      protocol: TCP
      targetPort: reloader-web
    selector:
      alertmanager: prometheus-kube-prometheus-alertmanager
      app.kubernetes.io/name: alertmanager
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2024-08-08T17:00:00Z"
    labels:
      app: kube-prometheus-stack-operator
      app.kubernetes.io/component: prometheus-operator
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: kube-prometheus-stack-prometheus-operator
      app.kubernetes.io/part-of: kube-prometheus-stack
      app.kubernetes.io/version: 61.7.2
      chart: kube-prometheus-stack-61.7.2
      heritage: Helm
      release: prometheus
    name: prometheus-kube-prometheus-operator
    namespace: monitoring
    resourceVersion: "14640"
    uid: fe72b191-4f29-49cc-aaca-9a12a3ea777c
  spec:
    clusterIP: 10.101.66.38
    clusterIPs:
    - 10.101.66.38
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: https
      port: 443
      protocol: TCP
      targetPort: https
    selector:
      app: kube-prometheus-stack-operator
      release: prometheus
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2024-08-08T17:00:00Z"
    labels:
      app: kube-prometheus-stack-prometheus
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/part-of: kube-prometheus-stack
      app.kubernetes.io/version: 61.7.2
      chart: kube-prometheus-stack-61.7.2
      heritage: Helm
      release: prometheus
      self-monitor: "true"
    name: prometheus-kube-prometheus-prometheus
    namespace: monitoring
    resourceVersion: "14644"
    uid: 199445ba-9d1f-4d36-aa23-f146ef1b722a
  spec:
    clusterIP: 10.109.45.90
    clusterIPs:
    - 10.109.45.90
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: http-web
      port: 9090
      protocol: TCP
      targetPort: 9090
    - appProtocol: http
      name: reloader-web
      port: 8080
      protocol: TCP
      targetPort: reloader-web
    selector:
      app.kubernetes.io/name: prometheus
      operator.prometheus.io/name: prometheus-kube-prometheus-prometheus
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
      prometheus.io/scrape: "true"
    creationTimestamp: "2024-08-08T14:32:42Z"
    labels:
      app.kubernetes.io/component: metrics
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: kube-state-metrics
      app.kubernetes.io/part-of: kube-state-metrics
      app.kubernetes.io/version: 2.13.0
      helm.sh/chart: kube-state-metrics-5.25.1
      release: prometheus
    name: prometheus-kube-state-metrics
    namespace: monitoring
    resourceVersion: "14613"
    uid: 6621f912-cde8-4161-aae4-f6680ffdbd8f
  spec:
    clusterIP: 10.105.228.215
    clusterIPs:
    - 10.105.228.215
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: http
      port: 8080
      protocol: TCP
      targetPort: 8080
    selector:
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/name: kube-state-metrics
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    creationTimestamp: "2024-08-08T17:00:01Z"
    labels:
      managed-by: prometheus-operator
      operated-prometheus: "true"
    name: prometheus-operated
    namespace: monitoring
    ownerReferences:
    - apiVersion: monitoring.coreos.com/v1
      kind: Prometheus
      name: prometheus-kube-prometheus-prometheus
      uid: 3454c7cc-839a-4035-9575-11fb656bf1f0
    resourceVersion: "14751"
    uid: 4cbfe028-e351-435f-bf0b-b368fca41147
  spec:
    clusterIP: None
    clusterIPs:
    - None
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: http-web
      port: 9090
      protocol: TCP
      targetPort: http-web
    selector:
      app.kubernetes.io/name: prometheus
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
      prometheus.io/scrape: "true"
    creationTimestamp: "2024-08-08T14:32:42Z"
    labels:
      app.kubernetes.io/component: metrics
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: prometheus-node-exporter
      app.kubernetes.io/part-of: prometheus-node-exporter
      app.kubernetes.io/version: 1.8.2
      helm.sh/chart: prometheus-node-exporter-4.37.3
      jobLabel: node-exporter
      release: prometheus
    name: prometheus-prometheus-node-exporter
    namespace: monitoring
    resourceVersion: "14617"
    uid: 64245811-6cbe-4d72-b0e7-32fdd84b0514
  spec:
    clusterIP: 10.108.176.152
    clusterIPs:
    - 10.108.176.152
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: http-metrics
      port: 9100
      protocol: TCP
      targetPort: 9100
    selector:
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/name: prometheus-node-exporter
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: apps/v1
  kind: DaemonSet
  metadata:
    annotations:
      deprecated.daemonset.template.generation: "1"
    creationTimestamp: "2024-08-08T13:10:16Z"
    generation: 1
    labels:
      k8s-app: kube-proxy
    name: kube-proxy
    namespace: kube-system
    resourceVersion: "19793"
    uid: 65e3aa45-28c8-44a5-9a3e-8cd3a69fefbe
  spec:
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: kube-proxy
    template:
      metadata:
        creationTimestamp: null
        labels:
          k8s-app: kube-proxy
      spec:
        containers:
        - command:
          - /usr/local/bin/kube-proxy
          - --config=/var/lib/kube-proxy/config.conf
          - --hostname-override=$(NODE_NAME)
          env:
          - name: NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          image: registry.k8s.io/kube-proxy:v1.30.0
          imagePullPolicy: IfNotPresent
          name: kube-proxy
          resources: {}
          securityContext:
            privileged: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /var/lib/kube-proxy
            name: kube-proxy
          - mountPath: /run/xtables.lock
            name: xtables-lock
          - mountPath: /lib/modules
            name: lib-modules
            readOnly: true
        dnsPolicy: ClusterFirst
        hostNetwork: true
        nodeSelector:
          kubernetes.io/os: linux
        priorityClassName: system-node-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: kube-proxy
        serviceAccountName: kube-proxy
        terminationGracePeriodSeconds: 30
        tolerations:
        - operator: Exists
        volumes:
        - configMap:
            defaultMode: 420
            name: kube-proxy
          name: kube-proxy
        - hostPath:
            path: /run/xtables.lock
            type: FileOrCreate
          name: xtables-lock
        - hostPath:
            path: /lib/modules
            type: ""
          name: lib-modules
    updateStrategy:
      rollingUpdate:
        maxSurge: 0
        maxUnavailable: 1
      type: RollingUpdate
  status:
    currentNumberScheduled: 1
    desiredNumberScheduled: 1
    numberAvailable: 1
    numberMisscheduled: 0
    numberReady: 1
    observedGeneration: 1
    updatedNumberScheduled: 1
- apiVersion: apps/v1
  kind: DaemonSet
  metadata:
    annotations:
      deprecated.daemonset.template.generation: "2"
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2024-08-08T14:32:42Z"
    generation: 2
    labels:
      app.kubernetes.io/component: metrics
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: prometheus-node-exporter
      app.kubernetes.io/part-of: prometheus-node-exporter
      app.kubernetes.io/version: 1.8.2
      helm.sh/chart: prometheus-node-exporter-4.37.3
      jobLabel: node-exporter
      release: prometheus
    name: prometheus-prometheus-node-exporter
    namespace: monitoring
    resourceVersion: "19783"
    uid: 1a27937e-2e58-492e-94ad-9314599b816f
  spec:
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app.kubernetes.io/instance: prometheus
        app.kubernetes.io/name: prometheus-node-exporter
    template:
      metadata:
        annotations:
          cluster-autoscaler.kubernetes.io/safe-to-evict: "true"
        creationTimestamp: null
        labels:
          app.kubernetes.io/component: metrics
          app.kubernetes.io/instance: prometheus
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/name: prometheus-node-exporter
          app.kubernetes.io/part-of: prometheus-node-exporter
          app.kubernetes.io/version: 1.8.2
          helm.sh/chart: prometheus-node-exporter-4.37.3
          jobLabel: node-exporter
          release: prometheus
      spec:
        automountServiceAccountToken: false
        containers:
        - args:
          - --path.procfs=/host/proc
          - --path.sysfs=/host/sys
          - --path.rootfs=/host/root
          - --path.udev.data=/host/root/run/udev/data
          - --web.listen-address=[$(HOST_IP)]:9100
          - --collector.filesystem.mount-points-exclude=^/(dev|proc|sys|var/lib/docker/.+|var/lib/kubelet/.+)($|/)
          - --collector.filesystem.fs-types-exclude=^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs)$
          env:
          - name: HOST_IP
            value: 0.0.0.0
          image: quay.io/prometheus/node-exporter:v1.8.2
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: 9100
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: node-exporter
          ports:
          - containerPort: 9100
            name: http-metrics
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: 9100
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          securityContext:
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /host/proc
            name: proc
            readOnly: true
          - mountPath: /host/sys
            name: sys
            readOnly: true
          - mountPath: /host/root
            mountPropagation: HostToContainer
            name: root
            readOnly: true
        dnsPolicy: ClusterFirst
        hostNetwork: true
        hostPID: true
        nodeSelector:
          kubernetes.io/os: linux
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 65534
          runAsGroup: 65534
          runAsNonRoot: true
          runAsUser: 65534
        serviceAccount: prometheus-prometheus-node-exporter
        serviceAccountName: prometheus-prometheus-node-exporter
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          operator: Exists
        volumes:
        - hostPath:
            path: /proc
            type: ""
          name: proc
        - hostPath:
            path: /sys
            type: ""
          name: sys
        - hostPath:
            path: /
            type: ""
          name: root
    updateStrategy:
      rollingUpdate:
        maxSurge: 0
        maxUnavailable: 1
      type: RollingUpdate
  status:
    currentNumberScheduled: 1
    desiredNumberScheduled: 1
    numberAvailable: 1
    numberMisscheduled: 0
    numberReady: 1
    observedGeneration: 2
    updatedNumberScheduled: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      meta.helm.sh/release-name: ingress-app
      meta.helm.sh/release-namespace: default
    creationTimestamp: "2024-08-08T17:30:13Z"
    generation: 1
    labels:
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: ingress-app
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: ingress-nginx
      app.kubernetes.io/part-of: ingress-nginx
      app.kubernetes.io/version: 1.11.1
      helm.sh/chart: ingress-nginx-4.11.1
    name: ingress-app-ingress-nginx-controller
    namespace: default
    resourceVersion: "26042"
    uid: fdaaf79c-cfe5-4c76-8f4a-701c2bb6565b
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app.kubernetes.io/component: controller
        app.kubernetes.io/instance: ingress-app
        app.kubernetes.io/name: ingress-nginx
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        creationTimestamp: null
        labels:
          app.kubernetes.io/component: controller
          app.kubernetes.io/instance: ingress-app
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/name: ingress-nginx
          app.kubernetes.io/part-of: ingress-nginx
          app.kubernetes.io/version: 1.11.1
          helm.sh/chart: ingress-nginx-4.11.1
      spec:
        containers:
        - args:
          - /nginx-ingress-controller
          - --publish-service=$(POD_NAMESPACE)/ingress-app-ingress-nginx-controller
          - --election-id=ingress-app-ingress-nginx-leader
          - --controller-class=k8s.io/ingress-nginx
          - --ingress-class=nginx
          - --configmap=$(POD_NAMESPACE)/ingress-app-ingress-nginx-controller
          - --validating-webhook=:8443
          - --validating-webhook-certificate=/usr/local/certificates/cert
          - --validating-webhook-key=/usr/local/certificates/key
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: LD_PRELOAD
            value: /usr/local/lib/libmimalloc.so
          image: registry.k8s.io/ingress-nginx/controller:v1.11.1@sha256:e6439a12b52076965928e83b7b56aae6731231677b01e81818bce7fa5c60161a
          imagePullPolicy: IfNotPresent
          lifecycle:
            preStop:
              exec:
                command:
                - /wait-shutdown
          livenessProbe:
            failureThreshold: 5
            httpGet:
              path: /healthz
              port: 10254
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: controller
          ports:
          - containerPort: 80
            name: http
            protocol: TCP
          - containerPort: 443
            name: https
            protocol: TCP
          - containerPort: 10254
            name: metrics
            protocol: TCP
          - containerPort: 8443
            name: webhook
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 10254
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            requests:
              cpu: 100m
              memory: 90Mi
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              add:
              - NET_BIND_SERVICE
              drop:
              - ALL
            readOnlyRootFilesystem: false
            runAsNonRoot: true
            runAsUser: 101
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /usr/local/certificates/
            name: webhook-cert
            readOnly: true
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/os: linux
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: ingress-app-ingress-nginx
        serviceAccountName: ingress-app-ingress-nginx
        terminationGracePeriodSeconds: 300
        volumes:
        - name: webhook-cert
          secret:
            defaultMode: 420
            secretName: ingress-app-ingress-nginx-admission
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2024-08-08T17:30:13Z"
      lastUpdateTime: "2024-08-08T17:30:23Z"
      message: ReplicaSet "ingress-app-ingress-nginx-controller-544f5dfc8f" has successfully
        progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2024-08-11T12:58:26Z"
      lastUpdateTime: "2024-08-11T12:58:26Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"app":"ml-api"},"name":"ml-api-deployment","namespace":"default"},"spec":{"replicas":1,"selector":{"matchLabels":{"app":"ml-api"}},"template":{"metadata":{"labels":{"app":"ml-api"}},"spec":{"containers":[{"env":[{"name":"FLASK_ENV","value":"production"}],"image":"shreyas2204/ml-api:latest","name":"ml-api","ports":[{"containerPort":5000}]}]}}}}
    creationTimestamp: "2024-08-11T14:54:55Z"
    generation: 1
    labels:
      app: ml-api
    name: ml-api-deployment
    namespace: default
    resourceVersion: "34158"
    uid: 25d3f8e7-f525-402c-9242-61456c8b768a
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: ml-api
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: ml-api
      spec:
        containers:
        - env:
          - name: FLASK_ENV
            value: production
          image: shreyas2204/ml-api:latest
          imagePullPolicy: Always
          name: ml-api
          ports:
          - containerPort: 5000
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2024-08-11T14:55:16Z"
      lastUpdateTime: "2024-08-11T14:55:16Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2024-08-11T14:54:55Z"
      lastUpdateTime: "2024-08-11T14:55:16Z"
      message: ReplicaSet "ml-api-deployment-548d698969" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"app":"nodeapp"},"name":"nodeapp-deployment","namespace":"default"},"spec":{"replicas":1,"selector":{"matchLabels":{"app":"nodeapp"}},"template":{"metadata":{"labels":{"app":"nodeapp"}},"spec":{"containers":[{"image":"shreyas2204/my-node-app","name":"nodeserver","ports":[{"containerPort":4000}]}]}}}}
    creationTimestamp: "2024-08-08T13:12:25Z"
    generation: 6
    labels:
      app: nodeapp
    name: nodeapp-deployment
    namespace: default
    resourceVersion: "21262"
    uid: b04283ca-6c88-4d47-b92d-eb0e6515a44b
  spec:
    progressDeadlineSeconds: 600
    replicas: 5
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: nodeapp
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: nodeapp
      spec:
        containers:
        - image: shreyas2204/my-node-app
          imagePullPolicy: Always
          name: nodeserver
          ports:
          - containerPort: 4000
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 5
    conditions:
    - lastTransitionTime: "2024-08-08T13:12:25Z"
      lastUpdateTime: "2024-08-08T13:12:32Z"
      message: ReplicaSet "nodeapp-deployment-6cc654cb66" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2024-08-11T02:16:11Z"
      lastUpdateTime: "2024-08-11T02:16:11Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 6
    readyReplicas: 5
    replicas: 5
    updatedReplicas: 5
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "3"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"app.kubernetes.io/component":"controller","app.kubernetes.io/instance":"ingress-nginx","app.kubernetes.io/name":"ingress-nginx"},"name":"ingress-nginx-controller","namespace":"ingress-nginx"},"spec":{"minReadySeconds":0,"revisionHistoryLimit":10,"selector":{"matchLabels":{"app.kubernetes.io/component":"controller","app.kubernetes.io/instance":"ingress-nginx","app.kubernetes.io/name":"ingress-nginx"}},"strategy":{"rollingUpdate":{"maxUnavailable":1},"type":"RollingUpdate"},"template":{"metadata":{"labels":{"app.kubernetes.io/component":"controller","app.kubernetes.io/instance":"ingress-nginx","app.kubernetes.io/name":"ingress-nginx","gcp-auth-skip-secret":"true"}},"spec":{"containers":[{"args":["/nginx-ingress-controller","--election-id=ingress-nginx-leader","--controller-class=k8s.io/ingress-nginx","--watch-ingress-without-class=true","--configmap=$(POD_NAMESPACE)/ingress-nginx-controller","--tcp-services-configmap=$(POD_NAMESPACE)/tcp-services","--udp-services-configmap=$(POD_NAMESPACE)/udp-services","--validating-webhook=:8443","--validating-webhook-certificate=/usr/local/certificates/cert","--validating-webhook-key=/usr/local/certificates/key"],"env":[{"name":"POD_NAME","valueFrom":{"fieldRef":{"fieldPath":"metadata.name"}}},{"name":"POD_NAMESPACE","valueFrom":{"fieldRef":{"fieldPath":"metadata.namespace"}}},{"name":"LD_PRELOAD","value":"/usr/local/lib/libmimalloc.so"}],"image":"registry.k8s.io/ingress-nginx/controller:v1.10.1@sha256:e24f39d3eed6bcc239a56f20098878845f62baa34b9f2be2fd2c38ce9fb0f29e","imagePullPolicy":"IfNotPresent","lifecycle":{"preStop":{"exec":{"command":["/wait-shutdown"]}}},"livenessProbe":{"failureThreshold":5,"httpGet":{"path":"/healthz","port":10254,"scheme":"HTTP"},"initialDelaySeconds":10,"periodSeconds":10,"successThreshold":1,"timeoutSeconds":1},"name":"controller","ports":[{"containerPort":80,"hostPort":80,"name":"http","protocol":"TCP"},{"containerPort":443,"hostPort":443,"name":"https","protocol":"TCP"},{"containerPort":8443,"name":"webhook","protocol":"TCP"}],"readinessProbe":{"failureThreshold":3,"httpGet":{"path":"/healthz","port":10254,"scheme":"HTTP"},"initialDelaySeconds":10,"periodSeconds":10,"successThreshold":1,"timeoutSeconds":1},"resources":{"requests":{"cpu":"100m","memory":"90Mi"}},"securityContext":{"allowPrivilegeEscalation":true,"capabilities":{"add":["NET_BIND_SERVICE"],"drop":["ALL"]},"runAsUser":101},"volumeMounts":[{"mountPath":"/usr/local/certificates/","name":"webhook-cert","readOnly":true}]}],"dnsPolicy":"ClusterFirst","nodeSelector":{"kubernetes.io/os":"linux","minikube.k8s.io/primary":"true"},"serviceAccountName":"ingress-nginx","terminationGracePeriodSeconds":0,"tolerations":[{"effect":"NoSchedule","key":"node-role.kubernetes.io/master","operator":"Equal"}],"volumes":[{"name":"webhook-cert","secret":{"secretName":"ingress-nginx-admission"}}]}}}}
    creationTimestamp: "2024-08-08T16:24:08Z"
    generation: 3
    labels:
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: ingress-nginx
      app.kubernetes.io/name: ingress-nginx
    name: ingress-nginx-controller
    namespace: ingress-nginx
    resourceVersion: "26066"
    uid: b2a1138e-5cd0-456f-a3b6-8f8e4ff497e2
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app.kubernetes.io/component: controller
        app.kubernetes.io/instance: ingress-nginx
        app.kubernetes.io/name: ingress-nginx
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 1
      type: RollingUpdate
    template:
      metadata:
        creationTimestamp: null
        labels:
          app.kubernetes.io/component: controller
          app.kubernetes.io/instance: ingress-nginx
          app.kubernetes.io/name: ingress-nginx
          gcp-auth-skip-secret: "true"
      spec:
        containers:
        - args:
          - /nginx-ingress-controller
          - --election-id=ingress-nginx-leader
          - --controller-class=k8s.io/ingress-nginx
          - --watch-ingress-without-class=true
          - --configmap=$(POD_NAMESPACE)/ingress-nginx-controller
          - --tcp-services-configmap=$(POD_NAMESPACE)/tcp-services
          - --udp-services-configmap=$(POD_NAMESPACE)/udp-services
          - --validating-webhook=:8443
          - --validating-webhook-certificate=/usr/local/certificates/cert
          - --validating-webhook-key=/usr/local/certificates/key
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: LD_PRELOAD
            value: /usr/local/lib/libmimalloc.so
          image: registry.k8s.io/ingress-nginx/controller:v1.10.1@sha256:e24f39d3eed6bcc239a56f20098878845f62baa34b9f2be2fd2c38ce9fb0f29e
          imagePullPolicy: IfNotPresent
          lifecycle:
            preStop:
              exec:
                command:
                - /wait-shutdown
          livenessProbe:
            failureThreshold: 5
            httpGet:
              path: /healthz
              port: 10254
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: controller
          ports:
          - containerPort: 80
            hostPort: 80
            name: http
            protocol: TCP
          - containerPort: 443
            hostPort: 443
            name: https
            protocol: TCP
          - containerPort: 8443
            name: webhook
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 10254
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            requests:
              cpu: 100m
              memory: 90Mi
          securityContext:
            allowPrivilegeEscalation: true
            capabilities:
              add:
              - NET_BIND_SERVICE
              drop:
              - ALL
            runAsUser: 101
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /usr/local/certificates/
            name: webhook-cert
            readOnly: true
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/os: linux
          minikube.k8s.io/primary: "true"
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: ingress-nginx
        serviceAccountName: ingress-nginx
        terminationGracePeriodSeconds: 0
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
          operator: Equal
        volumes:
        - name: webhook-cert
          secret:
            defaultMode: 420
            secretName: ingress-nginx-admission
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2024-08-08T16:24:08Z"
      lastUpdateTime: "2024-08-08T16:24:08Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2024-08-11T02:16:45Z"
      lastUpdateTime: "2024-08-11T02:16:45Z"
      message: ReplicaSet "ingress-nginx-controller-768f948f8f" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    observedGeneration: 3
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2024-08-08T13:10:16Z"
    generation: 2
    labels:
      k8s-app: kube-dns
    name: coredns
    namespace: kube-system
    resourceVersion: "26059"
    uid: 8b3618a6-a2c6-4d86-8b3d-df271725ae87
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: kube-dns
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 1
      type: RollingUpdate
    template:
      metadata:
        creationTimestamp: null
        labels:
          k8s-app: kube-dns
      spec:
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchExpressions:
                  - key: k8s-app
                    operator: In
                    values:
                    - kube-dns
                topologyKey: kubernetes.io/hostname
              weight: 100
        containers:
        - args:
          - -conf
          - /etc/coredns/Corefile
          image: registry.k8s.io/coredns/coredns:v1.11.1
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 5
            httpGet:
              path: /health
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: coredns
          ports:
          - containerPort: 53
            name: dns
            protocol: UDP
          - containerPort: 53
            name: dns-tcp
            protocol: TCP
          - containerPort: 9153
            name: metrics
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /ready
              port: 8181
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            limits:
              memory: 170Mi
            requests:
              cpu: 100m
              memory: 70Mi
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              add:
              - NET_BIND_SERVICE
              drop:
              - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/coredns
            name: config-volume
            readOnly: true
        dnsPolicy: Default
        nodeSelector:
          kubernetes.io/os: linux
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: coredns
        serviceAccountName: coredns
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
        volumes:
        - configMap:
            defaultMode: 420
            items:
            - key: Corefile
              path: Corefile
            name: coredns
          name: config-volume
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2024-08-08T13:10:31Z"
      lastUpdateTime: "2024-08-08T13:10:31Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2024-08-08T13:10:31Z"
      lastUpdateTime: "2024-08-08T13:10:31Z"
      message: ReplicaSet "coredns-7db6d8ff4d" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    observedGeneration: 2
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2024-08-08T17:00:00Z"
    generation: 1
    labels:
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: grafana
      app.kubernetes.io/version: 11.1.0
      helm.sh/chart: grafana-8.3.8
    name: prometheus-grafana
    namespace: monitoring
    resourceVersion: "19808"
    uid: 369c9b2d-e36b-45fe-a219-677b5edfbc85
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app.kubernetes.io/instance: prometheus
        app.kubernetes.io/name: grafana
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        annotations:
          checksum/config: 0e9cbd0ea8e24e32f7dfca5bab17a2ba05652642f0a09a4882833ae88e4cc4a3
          checksum/sc-dashboard-provider-config: e70bf6a851099d385178a76de9757bb0bef8299da6d8443602590e44f05fdf24
          checksum/secret: 032056e9c62bbe9d1daa41ee49cd3d9524c076f51ca4c65adadf4ef08ef28712
          kubectl.kubernetes.io/default-container: grafana
        creationTimestamp: null
        labels:
          app.kubernetes.io/instance: prometheus
          app.kubernetes.io/name: grafana
      spec:
        automountServiceAccountToken: true
        containers:
        - env:
          - name: METHOD
            value: WATCH
          - name: LABEL
            value: grafana_dashboard
          - name: LABEL_VALUE
            value: "1"
          - name: FOLDER
            value: /tmp/dashboards
          - name: RESOURCE
            value: both
          - name: NAMESPACE
            value: ALL
          - name: REQ_USERNAME
            valueFrom:
              secretKeyRef:
                key: admin-user
                name: prometheus-grafana
          - name: REQ_PASSWORD
            valueFrom:
              secretKeyRef:
                key: admin-password
                name: prometheus-grafana
          - name: REQ_URL
            value: http://localhost:3000/api/admin/provisioning/dashboards/reload
          - name: REQ_METHOD
            value: POST
          image: quay.io/kiwigrid/k8s-sidecar:1.27.4
          imagePullPolicy: IfNotPresent
          name: grafana-sc-dashboard
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /tmp/dashboards
            name: sc-dashboard-volume
        - env:
          - name: METHOD
            value: WATCH
          - name: LABEL
            value: grafana_datasource
          - name: LABEL_VALUE
            value: "1"
          - name: FOLDER
            value: /etc/grafana/provisioning/datasources
          - name: RESOURCE
            value: both
          - name: REQ_USERNAME
            valueFrom:
              secretKeyRef:
                key: admin-user
                name: prometheus-grafana
          - name: REQ_PASSWORD
            valueFrom:
              secretKeyRef:
                key: admin-password
                name: prometheus-grafana
          - name: REQ_URL
            value: http://localhost:3000/api/admin/provisioning/datasources/reload
          - name: REQ_METHOD
            value: POST
          image: quay.io/kiwigrid/k8s-sidecar:1.27.4
          imagePullPolicy: IfNotPresent
          name: grafana-sc-datasources
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/grafana/provisioning/datasources
            name: sc-datasources-volume
        - env:
          - name: POD_IP
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: status.podIP
          - name: GF_SECURITY_ADMIN_USER
            valueFrom:
              secretKeyRef:
                key: admin-user
                name: prometheus-grafana
          - name: GF_SECURITY_ADMIN_PASSWORD
            valueFrom:
              secretKeyRef:
                key: admin-password
                name: prometheus-grafana
          - name: GF_PATHS_DATA
            value: /var/lib/grafana/
          - name: GF_PATHS_LOGS
            value: /var/log/grafana
          - name: GF_PATHS_PLUGINS
            value: /var/lib/grafana/plugins
          - name: GF_PATHS_PROVISIONING
            value: /etc/grafana/provisioning
          image: docker.io/grafana/grafana:11.1.0
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 10
            httpGet:
              path: /api/health
              port: 3000
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 30
          name: grafana
          ports:
          - containerPort: 3000
            name: grafana
            protocol: TCP
          - containerPort: 9094
            name: gossip-tcp
            protocol: TCP
          - containerPort: 9094
            name: gossip-udp
            protocol: UDP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /api/health
              port: 3000
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/grafana/grafana.ini
            name: config
            subPath: grafana.ini
          - mountPath: /var/lib/grafana
            name: storage
          - mountPath: /tmp/dashboards
            name: sc-dashboard-volume
          - mountPath: /etc/grafana/provisioning/dashboards/sc-dashboardproviders.yaml
            name: sc-dashboard-provider
            subPath: provider.yaml
          - mountPath: /etc/grafana/provisioning/datasources
            name: sc-datasources-volume
        dnsPolicy: ClusterFirst
        enableServiceLinks: true
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 472
          runAsGroup: 472
          runAsNonRoot: true
          runAsUser: 472
        serviceAccount: prometheus-grafana
        serviceAccountName: prometheus-grafana
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: prometheus-grafana
          name: config
        - emptyDir: {}
          name: storage
        - emptyDir: {}
          name: sc-dashboard-volume
        - configMap:
            defaultMode: 420
            name: prometheus-grafana-config-dashboards
          name: sc-dashboard-provider
        - emptyDir: {}
          name: sc-datasources-volume
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2024-08-08T17:00:00Z"
      lastUpdateTime: "2024-08-08T17:00:11Z"
      message: ReplicaSet "prometheus-grafana-648c7ff88d" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2024-08-10T06:02:37Z"
      lastUpdateTime: "2024-08-10T06:02:37Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2024-08-08T17:00:00Z"
    generation: 1
    labels:
      app: kube-prometheus-stack-operator
      app.kubernetes.io/component: prometheus-operator
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: kube-prometheus-stack-prometheus-operator
      app.kubernetes.io/part-of: kube-prometheus-stack
      app.kubernetes.io/version: 61.7.2
      chart: kube-prometheus-stack-61.7.2
      heritage: Helm
      release: prometheus
    name: prometheus-kube-prometheus-operator
    namespace: monitoring
    resourceVersion: "25999"
    uid: 3ab8f2dd-3624-4302-a54b-8776f9ad0836
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: kube-prometheus-stack-operator
        release: prometheus
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: kube-prometheus-stack-operator
          app.kubernetes.io/component: prometheus-operator
          app.kubernetes.io/instance: prometheus
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/name: kube-prometheus-stack-prometheus-operator
          app.kubernetes.io/part-of: kube-prometheus-stack
          app.kubernetes.io/version: 61.7.2
          chart: kube-prometheus-stack-61.7.2
          heritage: Helm
          release: prometheus
      spec:
        automountServiceAccountToken: true
        containers:
        - args:
          - --kubelet-service=kube-system/prometheus-kube-prometheus-kubelet
          - --localhost=127.0.0.1
          - --prometheus-config-reloader=quay.io/prometheus-operator/prometheus-config-reloader:v0.75.2
          - --config-reloader-cpu-request=0
          - --config-reloader-cpu-limit=0
          - --config-reloader-memory-request=0
          - --config-reloader-memory-limit=0
          - --thanos-default-base-image=quay.io/thanos/thanos:v0.36.0
          - --secret-field-selector=type!=kubernetes.io/dockercfg,type!=kubernetes.io/service-account-token,type!=helm.sh/release.v1
          - --web.enable-tls=true
          - --web.cert-file=/cert/cert
          - --web.key-file=/cert/key
          - --web.listen-address=:10250
          - --web.tls-min-version=VersionTLS13
          env:
          - name: GOGC
            value: "30"
          image: quay.io/prometheus-operator/prometheus-operator:v0.75.2
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: https
              scheme: HTTPS
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: kube-prometheus-stack
          ports:
          - containerPort: 10250
            name: https
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: https
              scheme: HTTPS
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /cert
            name: tls-secret
            readOnly: true
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 65534
          runAsGroup: 65534
          runAsNonRoot: true
          runAsUser: 65534
          seccompProfile:
            type: RuntimeDefault
        serviceAccount: prometheus-kube-prometheus-operator
        serviceAccountName: prometheus-kube-prometheus-operator
        terminationGracePeriodSeconds: 30
        volumes:
        - name: tls-secret
          secret:
            defaultMode: 420
            secretName: prometheus-kube-prometheus-admission
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2024-08-08T17:00:00Z"
      lastUpdateTime: "2024-08-08T17:00:02Z"
      message: ReplicaSet "prometheus-kube-prometheus-operator-597f45494f" has successfully
        progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2024-08-11T12:58:12Z"
      lastUpdateTime: "2024-08-11T12:58:12Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "2"
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2024-08-08T14:32:42Z"
    generation: 2
    labels:
      app.kubernetes.io/component: metrics
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: kube-state-metrics
      app.kubernetes.io/part-of: kube-state-metrics
      app.kubernetes.io/version: 2.13.0
      helm.sh/chart: kube-state-metrics-5.25.1
      release: prometheus
    name: prometheus-kube-state-metrics
    namespace: monitoring
    resourceVersion: "26051"
    uid: 902b551b-ba72-4134-b784-558ed60636c3
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app.kubernetes.io/instance: prometheus
        app.kubernetes.io/name: kube-state-metrics
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        creationTimestamp: null
        labels:
          app.kubernetes.io/component: metrics
          app.kubernetes.io/instance: prometheus
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/name: kube-state-metrics
          app.kubernetes.io/part-of: kube-state-metrics
          app.kubernetes.io/version: 2.13.0
          helm.sh/chart: kube-state-metrics-5.25.1
          release: prometheus
      spec:
        automountServiceAccountToken: true
        containers:
        - args:
          - --port=8080
          - --resources=certificatesigningrequests,configmaps,cronjobs,daemonsets,deployments,endpoints,horizontalpodautoscalers,ingresses,jobs,leases,limitranges,mutatingwebhookconfigurations,namespaces,networkpolicies,nodes,persistentvolumeclaims,persistentvolumes,poddisruptionbudgets,pods,replicasets,replicationcontrollers,resourcequotas,secrets,services,statefulsets,storageclasses,validatingwebhookconfigurations,volumeattachments
          image: registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.13.0
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /livez
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: kube-state-metrics
          ports:
          - containerPort: 8080
            name: http
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /readyz
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 65534
          runAsGroup: 65534
          runAsNonRoot: true
          runAsUser: 65534
          seccompProfile:
            type: RuntimeDefault
        serviceAccount: prometheus-kube-state-metrics
        serviceAccountName: prometheus-kube-state-metrics
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2024-08-08T14:32:42Z"
      lastUpdateTime: "2024-08-08T17:00:11Z"
      message: ReplicaSet "prometheus-kube-state-metrics-688d66b5b8" has successfully
        progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2024-08-11T12:58:29Z"
      lastUpdateTime: "2024-08-11T12:58:29Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 2
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
      meta.helm.sh/release-name: ingress-app
      meta.helm.sh/release-namespace: default
    creationTimestamp: "2024-08-08T17:30:13Z"
    generation: 1
    labels:
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: ingress-app
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: ingress-nginx
      app.kubernetes.io/part-of: ingress-nginx
      app.kubernetes.io/version: 1.11.1
      helm.sh/chart: ingress-nginx-4.11.1
      pod-template-hash: 544f5dfc8f
    name: ingress-app-ingress-nginx-controller-544f5dfc8f
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: ingress-app-ingress-nginx-controller
      uid: fdaaf79c-cfe5-4c76-8f4a-701c2bb6565b
    resourceVersion: "26041"
    uid: b51212ec-9672-4663-9c71-ee97b342d70b
  spec:
    replicas: 1
    selector:
      matchLabels:
        app.kubernetes.io/component: controller
        app.kubernetes.io/instance: ingress-app
        app.kubernetes.io/name: ingress-nginx
        pod-template-hash: 544f5dfc8f
    template:
      metadata:
        creationTimestamp: null
        labels:
          app.kubernetes.io/component: controller
          app.kubernetes.io/instance: ingress-app
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/name: ingress-nginx
          app.kubernetes.io/part-of: ingress-nginx
          app.kubernetes.io/version: 1.11.1
          helm.sh/chart: ingress-nginx-4.11.1
          pod-template-hash: 544f5dfc8f
      spec:
        containers:
        - args:
          - /nginx-ingress-controller
          - --publish-service=$(POD_NAMESPACE)/ingress-app-ingress-nginx-controller
          - --election-id=ingress-app-ingress-nginx-leader
          - --controller-class=k8s.io/ingress-nginx
          - --ingress-class=nginx
          - --configmap=$(POD_NAMESPACE)/ingress-app-ingress-nginx-controller
          - --validating-webhook=:8443
          - --validating-webhook-certificate=/usr/local/certificates/cert
          - --validating-webhook-key=/usr/local/certificates/key
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: LD_PRELOAD
            value: /usr/local/lib/libmimalloc.so
          image: registry.k8s.io/ingress-nginx/controller:v1.11.1@sha256:e6439a12b52076965928e83b7b56aae6731231677b01e81818bce7fa5c60161a
          imagePullPolicy: IfNotPresent
          lifecycle:
            preStop:
              exec:
                command:
                - /wait-shutdown
          livenessProbe:
            failureThreshold: 5
            httpGet:
              path: /healthz
              port: 10254
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: controller
          ports:
          - containerPort: 80
            name: http
            protocol: TCP
          - containerPort: 443
            name: https
            protocol: TCP
          - containerPort: 10254
            name: metrics
            protocol: TCP
          - containerPort: 8443
            name: webhook
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 10254
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            requests:
              cpu: 100m
              memory: 90Mi
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              add:
              - NET_BIND_SERVICE
              drop:
              - ALL
            readOnlyRootFilesystem: false
            runAsNonRoot: true
            runAsUser: 101
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /usr/local/certificates/
            name: webhook-cert
            readOnly: true
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/os: linux
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: ingress-app-ingress-nginx
        serviceAccountName: ingress-app-ingress-nginx
        terminationGracePeriodSeconds: 300
        volumes:
        - name: webhook-cert
          secret:
            defaultMode: 420
            secretName: ingress-app-ingress-nginx-admission
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2024-08-11T14:54:55Z"
    generation: 1
    labels:
      app: ml-api
      pod-template-hash: 548d698969
    name: ml-api-deployment-548d698969
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: ml-api-deployment
      uid: 25d3f8e7-f525-402c-9242-61456c8b768a
    resourceVersion: "34157"
    uid: 12c9a921-aef1-4900-8f71-5d2ee2da8b74
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: ml-api
        pod-template-hash: 548d698969
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: ml-api
          pod-template-hash: 548d698969
      spec:
        containers:
        - env:
          - name: FLASK_ENV
            value: production
          image: shreyas2204/ml-api:latest
          imagePullPolicy: Always
          name: ml-api
          ports:
          - containerPort: 5000
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "5"
      deployment.kubernetes.io/max-replicas: "7"
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2024-08-08T13:12:25Z"
    generation: 6
    labels:
      app: nodeapp
      pod-template-hash: 6cc654cb66
    name: nodeapp-deployment-6cc654cb66
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: nodeapp-deployment
      uid: b04283ca-6c88-4d47-b92d-eb0e6515a44b
    resourceVersion: "21261"
    uid: 37defdaa-8d13-440f-90b5-6a469b04bb6d
  spec:
    replicas: 5
    selector:
      matchLabels:
        app: nodeapp
        pod-template-hash: 6cc654cb66
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: nodeapp
          pod-template-hash: 6cc654cb66
      spec:
        containers:
        - image: shreyas2204/my-node-app
          imagePullPolicy: Always
          name: nodeserver
          ports:
          - containerPort: 4000
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 5
    fullyLabeledReplicas: 5
    observedGeneration: 6
    readyReplicas: 5
    replicas: 5
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "2"
    creationTimestamp: "2024-08-08T16:39:48Z"
    generation: 2
    labels:
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: ingress-nginx
      app.kubernetes.io/name: ingress-nginx
      gcp-auth-skip-secret: "true"
      pod-template-hash: 567895b879
    name: ingress-nginx-controller-567895b879
    namespace: ingress-nginx
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: ingress-nginx-controller
      uid: b2a1138e-5cd0-456f-a3b6-8f8e4ff497e2
    resourceVersion: "19612"
    uid: 02724799-6758-42d1-a0b9-278e400d78d4
  spec:
    replicas: 0
    selector:
      matchLabels:
        app.kubernetes.io/component: controller
        app.kubernetes.io/instance: ingress-nginx
        app.kubernetes.io/name: ingress-nginx
        pod-template-hash: 567895b879
    template:
      metadata:
        creationTimestamp: null
        labels:
          app.kubernetes.io/component: controller
          app.kubernetes.io/instance: ingress-nginx
          app.kubernetes.io/name: ingress-nginx
          gcp-auth-skip-secret: "true"
          pod-template-hash: 567895b879
      spec:
        containers:
        - args:
          - /nginx-ingress-controller
          - --election-id=ingress-nginx-leader
          - --controller-class=k8s.io/ingress-nginx
          - --watch-ingress-without-class=true
          - --configmap=$(POD_NAMESPACE)/ingress-nginx-controller
          - --tcp-services-configmap=$(POD_NAMESPACE)/tcp-services
          - --udp-services-configmap=$(POD_NAMESPACE)/udp-services
          - --validating-webhook=:8443
          - --validating-webhook-certificate=/usr/local/certificates/cert
          - --validating-webhook-key=/usr/local/certificates/key
          - --enable-prometheus-metrics
          - --metrics-port=10254
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: LD_PRELOAD
            value: /usr/local/lib/libmimalloc.so
          image: registry.k8s.io/ingress-nginx/controller:v1.10.1@sha256:e24f39d3eed6bcc239a56f20098878845f62baa34b9f2be2fd2c38ce9fb0f29e
          imagePullPolicy: IfNotPresent
          lifecycle:
            preStop:
              exec:
                command:
                - /wait-shutdown
          livenessProbe:
            failureThreshold: 5
            httpGet:
              path: /healthz
              port: 10254
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: controller
          ports:
          - containerPort: 80
            hostPort: 80
            name: http
            protocol: TCP
          - containerPort: 443
            hostPort: 443
            name: https
            protocol: TCP
          - containerPort: 8443
            name: webhook
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 10254
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            requests:
              cpu: 100m
              memory: 90Mi
          securityContext:
            allowPrivilegeEscalation: true
            capabilities:
              add:
              - NET_BIND_SERVICE
              drop:
              - ALL
            runAsUser: 101
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /usr/local/certificates/
            name: webhook-cert
            readOnly: true
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/os: linux
          minikube.k8s.io/primary: "true"
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: ingress-nginx
        serviceAccountName: ingress-nginx
        terminationGracePeriodSeconds: 0
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
          operator: Equal
        volumes:
        - name: webhook-cert
          secret:
            defaultMode: 420
            secretName: ingress-nginx-admission
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "3"
      deployment.kubernetes.io/revision-history: "1"
    creationTimestamp: "2024-08-08T16:24:08Z"
    generation: 3
    labels:
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: ingress-nginx
      app.kubernetes.io/name: ingress-nginx
      gcp-auth-skip-secret: "true"
      pod-template-hash: 768f948f8f
    name: ingress-nginx-controller-768f948f8f
    namespace: ingress-nginx
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: ingress-nginx-controller
      uid: b2a1138e-5cd0-456f-a3b6-8f8e4ff497e2
    resourceVersion: "26065"
    uid: 2597efdf-f9b9-4984-a2da-858069135674
  spec:
    replicas: 1
    selector:
      matchLabels:
        app.kubernetes.io/component: controller
        app.kubernetes.io/instance: ingress-nginx
        app.kubernetes.io/name: ingress-nginx
        pod-template-hash: 768f948f8f
    template:
      metadata:
        creationTimestamp: null
        labels:
          app.kubernetes.io/component: controller
          app.kubernetes.io/instance: ingress-nginx
          app.kubernetes.io/name: ingress-nginx
          gcp-auth-skip-secret: "true"
          pod-template-hash: 768f948f8f
      spec:
        containers:
        - args:
          - /nginx-ingress-controller
          - --election-id=ingress-nginx-leader
          - --controller-class=k8s.io/ingress-nginx
          - --watch-ingress-without-class=true
          - --configmap=$(POD_NAMESPACE)/ingress-nginx-controller
          - --tcp-services-configmap=$(POD_NAMESPACE)/tcp-services
          - --udp-services-configmap=$(POD_NAMESPACE)/udp-services
          - --validating-webhook=:8443
          - --validating-webhook-certificate=/usr/local/certificates/cert
          - --validating-webhook-key=/usr/local/certificates/key
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: LD_PRELOAD
            value: /usr/local/lib/libmimalloc.so
          image: registry.k8s.io/ingress-nginx/controller:v1.10.1@sha256:e24f39d3eed6bcc239a56f20098878845f62baa34b9f2be2fd2c38ce9fb0f29e
          imagePullPolicy: IfNotPresent
          lifecycle:
            preStop:
              exec:
                command:
                - /wait-shutdown
          livenessProbe:
            failureThreshold: 5
            httpGet:
              path: /healthz
              port: 10254
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: controller
          ports:
          - containerPort: 80
            hostPort: 80
            name: http
            protocol: TCP
          - containerPort: 443
            hostPort: 443
            name: https
            protocol: TCP
          - containerPort: 8443
            name: webhook
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 10254
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            requests:
              cpu: 100m
              memory: 90Mi
          securityContext:
            allowPrivilegeEscalation: true
            capabilities:
              add:
              - NET_BIND_SERVICE
              drop:
              - ALL
            runAsUser: 101
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /usr/local/certificates/
            name: webhook-cert
            readOnly: true
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/os: linux
          minikube.k8s.io/primary: "true"
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: ingress-nginx
        serviceAccountName: ingress-nginx
        terminationGracePeriodSeconds: 0
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
          operator: Equal
        volumes:
        - name: webhook-cert
          secret:
            defaultMode: 420
            secretName: ingress-nginx-admission
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 3
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2024-08-08T13:10:31Z"
    generation: 1
    labels:
      k8s-app: kube-dns
      pod-template-hash: 7db6d8ff4d
    name: coredns-7db6d8ff4d
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: coredns
      uid: 8b3618a6-a2c6-4d86-8b3d-df271725ae87
    resourceVersion: "26058"
    uid: a73403f7-0086-44a7-8bec-c872be863ef9
  spec:
    replicas: 1
    selector:
      matchLabels:
        k8s-app: kube-dns
        pod-template-hash: 7db6d8ff4d
    template:
      metadata:
        creationTimestamp: null
        labels:
          k8s-app: kube-dns
          pod-template-hash: 7db6d8ff4d
      spec:
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchExpressions:
                  - key: k8s-app
                    operator: In
                    values:
                    - kube-dns
                topologyKey: kubernetes.io/hostname
              weight: 100
        containers:
        - args:
          - -conf
          - /etc/coredns/Corefile
          image: registry.k8s.io/coredns/coredns:v1.11.1
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 5
            httpGet:
              path: /health
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: coredns
          ports:
          - containerPort: 53
            name: dns
            protocol: UDP
          - containerPort: 53
            name: dns-tcp
            protocol: TCP
          - containerPort: 9153
            name: metrics
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /ready
              port: 8181
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            limits:
              memory: 170Mi
            requests:
              cpu: 100m
              memory: 70Mi
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              add:
              - NET_BIND_SERVICE
              drop:
              - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/coredns
            name: config-volume
            readOnly: true
        dnsPolicy: Default
        nodeSelector:
          kubernetes.io/os: linux
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: coredns
        serviceAccountName: coredns
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
        volumes:
        - configMap:
            defaultMode: 420
            items:
            - key: Corefile
              path: Corefile
            name: coredns
          name: config-volume
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2024-08-08T17:00:00Z"
    generation: 1
    labels:
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/name: grafana
      pod-template-hash: 648c7ff88d
    name: prometheus-grafana-648c7ff88d
    namespace: monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: prometheus-grafana
      uid: 369c9b2d-e36b-45fe-a219-677b5edfbc85
    resourceVersion: "19804"
    uid: 6a357f7e-1f3d-441a-afd3-51349063d3f9
  spec:
    replicas: 1
    selector:
      matchLabels:
        app.kubernetes.io/instance: prometheus
        app.kubernetes.io/name: grafana
        pod-template-hash: 648c7ff88d
    template:
      metadata:
        annotations:
          checksum/config: 0e9cbd0ea8e24e32f7dfca5bab17a2ba05652642f0a09a4882833ae88e4cc4a3
          checksum/sc-dashboard-provider-config: e70bf6a851099d385178a76de9757bb0bef8299da6d8443602590e44f05fdf24
          checksum/secret: 032056e9c62bbe9d1daa41ee49cd3d9524c076f51ca4c65adadf4ef08ef28712
          kubectl.kubernetes.io/default-container: grafana
        creationTimestamp: null
        labels:
          app.kubernetes.io/instance: prometheus
          app.kubernetes.io/name: grafana
          pod-template-hash: 648c7ff88d
      spec:
        automountServiceAccountToken: true
        containers:
        - env:
          - name: METHOD
            value: WATCH
          - name: LABEL
            value: grafana_dashboard
          - name: LABEL_VALUE
            value: "1"
          - name: FOLDER
            value: /tmp/dashboards
          - name: RESOURCE
            value: both
          - name: NAMESPACE
            value: ALL
          - name: REQ_USERNAME
            valueFrom:
              secretKeyRef:
                key: admin-user
                name: prometheus-grafana
          - name: REQ_PASSWORD
            valueFrom:
              secretKeyRef:
                key: admin-password
                name: prometheus-grafana
          - name: REQ_URL
            value: http://localhost:3000/api/admin/provisioning/dashboards/reload
          - name: REQ_METHOD
            value: POST
          image: quay.io/kiwigrid/k8s-sidecar:1.27.4
          imagePullPolicy: IfNotPresent
          name: grafana-sc-dashboard
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /tmp/dashboards
            name: sc-dashboard-volume
        - env:
          - name: METHOD
            value: WATCH
          - name: LABEL
            value: grafana_datasource
          - name: LABEL_VALUE
            value: "1"
          - name: FOLDER
            value: /etc/grafana/provisioning/datasources
          - name: RESOURCE
            value: both
          - name: REQ_USERNAME
            valueFrom:
              secretKeyRef:
                key: admin-user
                name: prometheus-grafana
          - name: REQ_PASSWORD
            valueFrom:
              secretKeyRef:
                key: admin-password
                name: prometheus-grafana
          - name: REQ_URL
            value: http://localhost:3000/api/admin/provisioning/datasources/reload
          - name: REQ_METHOD
            value: POST
          image: quay.io/kiwigrid/k8s-sidecar:1.27.4
          imagePullPolicy: IfNotPresent
          name: grafana-sc-datasources
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/grafana/provisioning/datasources
            name: sc-datasources-volume
        - env:
          - name: POD_IP
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: status.podIP
          - name: GF_SECURITY_ADMIN_USER
            valueFrom:
              secretKeyRef:
                key: admin-user
                name: prometheus-grafana
          - name: GF_SECURITY_ADMIN_PASSWORD
            valueFrom:
              secretKeyRef:
                key: admin-password
                name: prometheus-grafana
          - name: GF_PATHS_DATA
            value: /var/lib/grafana/
          - name: GF_PATHS_LOGS
            value: /var/log/grafana
          - name: GF_PATHS_PLUGINS
            value: /var/lib/grafana/plugins
          - name: GF_PATHS_PROVISIONING
            value: /etc/grafana/provisioning
          image: docker.io/grafana/grafana:11.1.0
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 10
            httpGet:
              path: /api/health
              port: 3000
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 30
          name: grafana
          ports:
          - containerPort: 3000
            name: grafana
            protocol: TCP
          - containerPort: 9094
            name: gossip-tcp
            protocol: TCP
          - containerPort: 9094
            name: gossip-udp
            protocol: UDP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /api/health
              port: 3000
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/grafana/grafana.ini
            name: config
            subPath: grafana.ini
          - mountPath: /var/lib/grafana
            name: storage
          - mountPath: /tmp/dashboards
            name: sc-dashboard-volume
          - mountPath: /etc/grafana/provisioning/dashboards/sc-dashboardproviders.yaml
            name: sc-dashboard-provider
            subPath: provider.yaml
          - mountPath: /etc/grafana/provisioning/datasources
            name: sc-datasources-volume
        dnsPolicy: ClusterFirst
        enableServiceLinks: true
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 472
          runAsGroup: 472
          runAsNonRoot: true
          runAsUser: 472
        serviceAccount: prometheus-grafana
        serviceAccountName: prometheus-grafana
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: prometheus-grafana
          name: config
        - emptyDir: {}
          name: storage
        - emptyDir: {}
          name: sc-dashboard-volume
        - configMap:
            defaultMode: 420
            name: prometheus-grafana-config-dashboards
          name: sc-dashboard-provider
        - emptyDir: {}
          name: sc-datasources-volume
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2024-08-08T17:00:00Z"
    generation: 1
    labels:
      app: kube-prometheus-stack-operator
      app.kubernetes.io/component: prometheus-operator
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: kube-prometheus-stack-prometheus-operator
      app.kubernetes.io/part-of: kube-prometheus-stack
      app.kubernetes.io/version: 61.7.2
      chart: kube-prometheus-stack-61.7.2
      heritage: Helm
      pod-template-hash: 597f45494f
      release: prometheus
    name: prometheus-kube-prometheus-operator-597f45494f
    namespace: monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: prometheus-kube-prometheus-operator
      uid: 3ab8f2dd-3624-4302-a54b-8776f9ad0836
    resourceVersion: "25998"
    uid: 1e4ec55a-0028-47f5-9ace-1c6cf887ece5
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: kube-prometheus-stack-operator
        pod-template-hash: 597f45494f
        release: prometheus
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: kube-prometheus-stack-operator
          app.kubernetes.io/component: prometheus-operator
          app.kubernetes.io/instance: prometheus
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/name: kube-prometheus-stack-prometheus-operator
          app.kubernetes.io/part-of: kube-prometheus-stack
          app.kubernetes.io/version: 61.7.2
          chart: kube-prometheus-stack-61.7.2
          heritage: Helm
          pod-template-hash: 597f45494f
          release: prometheus
      spec:
        automountServiceAccountToken: true
        containers:
        - args:
          - --kubelet-service=kube-system/prometheus-kube-prometheus-kubelet
          - --localhost=127.0.0.1
          - --prometheus-config-reloader=quay.io/prometheus-operator/prometheus-config-reloader:v0.75.2
          - --config-reloader-cpu-request=0
          - --config-reloader-cpu-limit=0
          - --config-reloader-memory-request=0
          - --config-reloader-memory-limit=0
          - --thanos-default-base-image=quay.io/thanos/thanos:v0.36.0
          - --secret-field-selector=type!=kubernetes.io/dockercfg,type!=kubernetes.io/service-account-token,type!=helm.sh/release.v1
          - --web.enable-tls=true
          - --web.cert-file=/cert/cert
          - --web.key-file=/cert/key
          - --web.listen-address=:10250
          - --web.tls-min-version=VersionTLS13
          env:
          - name: GOGC
            value: "30"
          image: quay.io/prometheus-operator/prometheus-operator:v0.75.2
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: https
              scheme: HTTPS
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: kube-prometheus-stack
          ports:
          - containerPort: 10250
            name: https
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: https
              scheme: HTTPS
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /cert
            name: tls-secret
            readOnly: true
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 65534
          runAsGroup: 65534
          runAsNonRoot: true
          runAsUser: 65534
          seccompProfile:
            type: RuntimeDefault
        serviceAccount: prometheus-kube-prometheus-operator
        serviceAccountName: prometheus-kube-prometheus-operator
        terminationGracePeriodSeconds: 30
        volumes:
        - name: tls-secret
          secret:
            defaultMode: 420
            secretName: prometheus-kube-prometheus-admission
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "2"
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2024-08-08T17:00:00Z"
    generation: 1
    labels:
      app.kubernetes.io/component: metrics
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: kube-state-metrics
      app.kubernetes.io/part-of: kube-state-metrics
      app.kubernetes.io/version: 2.13.0
      helm.sh/chart: kube-state-metrics-5.25.1
      pod-template-hash: 688d66b5b8
      release: prometheus
    name: prometheus-kube-state-metrics-688d66b5b8
    namespace: monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: prometheus-kube-state-metrics
      uid: 902b551b-ba72-4134-b784-558ed60636c3
    resourceVersion: "26050"
    uid: f4b90eeb-0bc8-4476-90be-f352e1f0328f
  spec:
    replicas: 1
    selector:
      matchLabels:
        app.kubernetes.io/instance: prometheus
        app.kubernetes.io/name: kube-state-metrics
        pod-template-hash: 688d66b5b8
    template:
      metadata:
        creationTimestamp: null
        labels:
          app.kubernetes.io/component: metrics
          app.kubernetes.io/instance: prometheus
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/name: kube-state-metrics
          app.kubernetes.io/part-of: kube-state-metrics
          app.kubernetes.io/version: 2.13.0
          helm.sh/chart: kube-state-metrics-5.25.1
          pod-template-hash: 688d66b5b8
          release: prometheus
      spec:
        automountServiceAccountToken: true
        containers:
        - args:
          - --port=8080
          - --resources=certificatesigningrequests,configmaps,cronjobs,daemonsets,deployments,endpoints,horizontalpodautoscalers,ingresses,jobs,leases,limitranges,mutatingwebhookconfigurations,namespaces,networkpolicies,nodes,persistentvolumeclaims,persistentvolumes,poddisruptionbudgets,pods,replicasets,replicationcontrollers,resourcequotas,secrets,services,statefulsets,storageclasses,validatingwebhookconfigurations,volumeattachments
          image: registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.13.0
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /livez
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: kube-state-metrics
          ports:
          - containerPort: 8080
            name: http
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /readyz
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 65534
          runAsGroup: 65534
          runAsNonRoot: true
          runAsUser: 65534
          seccompProfile:
            type: RuntimeDefault
        serviceAccount: prometheus-kube-state-metrics
        serviceAccountName: prometheus-kube-state-metrics
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2024-08-08T14:32:42Z"
    generation: 2
    labels:
      app.kubernetes.io/component: metrics
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: kube-state-metrics
      app.kubernetes.io/part-of: kube-state-metrics
      app.kubernetes.io/version: 2.13.0
      helm.sh/chart: kube-state-metrics-5.25.1
      pod-template-hash: 74cdb59bff
    name: prometheus-kube-state-metrics-74cdb59bff
    namespace: monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: prometheus-kube-state-metrics
      uid: 902b551b-ba72-4134-b784-558ed60636c3
    resourceVersion: "15019"
    uid: e77429b6-c865-4b3f-aa66-7dcfa8329d39
  spec:
    replicas: 0
    selector:
      matchLabels:
        app.kubernetes.io/instance: prometheus
        app.kubernetes.io/name: kube-state-metrics
        pod-template-hash: 74cdb59bff
    template:
      metadata:
        creationTimestamp: null
        labels:
          app.kubernetes.io/component: metrics
          app.kubernetes.io/instance: prometheus
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/name: kube-state-metrics
          app.kubernetes.io/part-of: kube-state-metrics
          app.kubernetes.io/version: 2.13.0
          helm.sh/chart: kube-state-metrics-5.25.1
          pod-template-hash: 74cdb59bff
      spec:
        automountServiceAccountToken: true
        containers:
        - args:
          - --port=8080
          - --resources=certificatesigningrequests,configmaps,cronjobs,daemonsets,deployments,endpoints,horizontalpodautoscalers,ingresses,jobs,leases,limitranges,mutatingwebhookconfigurations,namespaces,networkpolicies,nodes,persistentvolumeclaims,persistentvolumes,poddisruptionbudgets,pods,replicasets,replicationcontrollers,resourcequotas,secrets,services,statefulsets,storageclasses,validatingwebhookconfigurations,volumeattachments
          image: registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.13.0
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /livez
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: kube-state-metrics
          ports:
          - containerPort: 8080
            name: http
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /readyz
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 65534
          runAsGroup: 65534
          runAsNonRoot: true
          runAsUser: 65534
          seccompProfile:
            type: RuntimeDefault
        serviceAccount: prometheus-kube-state-metrics
        serviceAccountName: prometheus-kube-state-metrics
        terminationGracePeriodSeconds: 30
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: StatefulSet
  metadata:
    annotations:
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
      prometheus-operator-input-hash: "9387997950498179556"
    creationTimestamp: "2024-08-08T17:00:01Z"
    generation: 1
    labels:
      app: kube-prometheus-stack-alertmanager
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/part-of: kube-prometheus-stack
      app.kubernetes.io/version: 61.7.2
      chart: kube-prometheus-stack-61.7.2
      heritage: Helm
      managed-by: prometheus-operator
      release: prometheus
    name: alertmanager-prometheus-kube-prometheus-alertmanager
    namespace: monitoring
    ownerReferences:
    - apiVersion: monitoring.coreos.com/v1
      blockOwnerDeletion: true
      controller: true
      kind: Alertmanager
      name: prometheus-kube-prometheus-alertmanager
      uid: 73e8987a-5d71-4ec1-995f-e6dc3bdaf7e1
    resourceVersion: "19800"
    uid: feb21235-defb-404e-8d42-576aa68143a4
  spec:
    persistentVolumeClaimRetentionPolicy:
      whenDeleted: Retain
      whenScaled: Retain
    podManagementPolicy: Parallel
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        alertmanager: prometheus-kube-prometheus-alertmanager
        app.kubernetes.io/instance: prometheus-kube-prometheus-alertmanager
        app.kubernetes.io/managed-by: prometheus-operator
        app.kubernetes.io/name: alertmanager
    serviceName: alertmanager-operated
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/default-container: alertmanager
        creationTimestamp: null
        labels:
          alertmanager: prometheus-kube-prometheus-alertmanager
          app.kubernetes.io/instance: prometheus-kube-prometheus-alertmanager
          app.kubernetes.io/managed-by: prometheus-operator
          app.kubernetes.io/name: alertmanager
          app.kubernetes.io/version: 0.27.0
      spec:
        automountServiceAccountToken: true
        containers:
        - args:
          - --config.file=/etc/alertmanager/config_out/alertmanager.env.yaml
          - --storage.path=/alertmanager
          - --data.retention=120h
          - --cluster.listen-address=
          - --web.listen-address=:9093
          - --web.external-url=http://prometheus-kube-prometheus-alertmanager.monitoring:9093
          - --web.route-prefix=/
          - --cluster.label=monitoring/prometheus-kube-prometheus-alertmanager
          - --cluster.peer=alertmanager-prometheus-kube-prometheus-alertmanager-0.alertmanager-operated:9094
          - --cluster.reconnect-timeout=5m
          - --web.config.file=/etc/alertmanager/web_config/web-config.yaml
          env:
          - name: POD_IP
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: status.podIP
          image: quay.io/prometheus/alertmanager:v0.27.0
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 10
            httpGet:
              path: /-/healthy
              port: http-web
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 3
          name: alertmanager
          ports:
          - containerPort: 9093
            name: http-web
            protocol: TCP
          - containerPort: 9094
            name: mesh-tcp
            protocol: TCP
          - containerPort: 9094
            name: mesh-udp
            protocol: UDP
          readinessProbe:
            failureThreshold: 10
            httpGet:
              path: /-/ready
              port: http-web
              scheme: HTTP
            initialDelaySeconds: 3
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 3
          resources:
            requests:
              memory: 200Mi
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: FallbackToLogsOnError
          volumeMounts:
          - mountPath: /etc/alertmanager/config
            name: config-volume
          - mountPath: /etc/alertmanager/config_out
            name: config-out
            readOnly: true
          - mountPath: /etc/alertmanager/certs
            name: tls-assets
            readOnly: true
          - mountPath: /alertmanager
            name: alertmanager-prometheus-kube-prometheus-alertmanager-db
          - mountPath: /etc/alertmanager/web_config/web-config.yaml
            name: web-config
            readOnly: true
            subPath: web-config.yaml
        - args:
          - --listen-address=:8080
          - --reload-url=http://127.0.0.1:9093/-/reload
          - --config-file=/etc/alertmanager/config/alertmanager.yaml.gz
          - --config-envsubst-file=/etc/alertmanager/config_out/alertmanager.env.yaml
          - --watched-dir=/etc/alertmanager/config
          command:
          - /bin/prometheus-config-reloader
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: SHARD
            value: "-1"
          image: quay.io/prometheus-operator/prometheus-config-reloader:v0.75.2
          imagePullPolicy: IfNotPresent
          name: config-reloader
          ports:
          - containerPort: 8080
            name: reloader-web
            protocol: TCP
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: FallbackToLogsOnError
          volumeMounts:
          - mountPath: /etc/alertmanager/config
            name: config-volume
            readOnly: true
          - mountPath: /etc/alertmanager/config_out
            name: config-out
        dnsPolicy: ClusterFirst
        initContainers:
        - args:
          - --watch-interval=0
          - --listen-address=:8081
          - --config-file=/etc/alertmanager/config/alertmanager.yaml.gz
          - --config-envsubst-file=/etc/alertmanager/config_out/alertmanager.env.yaml
          - --watched-dir=/etc/alertmanager/config
          command:
          - /bin/prometheus-config-reloader
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: SHARD
            value: "-1"
          image: quay.io/prometheus-operator/prometheus-config-reloader:v0.75.2
          imagePullPolicy: IfNotPresent
          name: init-config-reloader
          ports:
          - containerPort: 8081
            name: reloader-web
            protocol: TCP
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: FallbackToLogsOnError
          volumeMounts:
          - mountPath: /etc/alertmanager/config
            name: config-volume
            readOnly: true
          - mountPath: /etc/alertmanager/config_out
            name: config-out
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 2000
          runAsGroup: 2000
          runAsNonRoot: true
          runAsUser: 1000
          seccompProfile:
            type: RuntimeDefault
        serviceAccount: prometheus-kube-prometheus-alertmanager
        serviceAccountName: prometheus-kube-prometheus-alertmanager
        terminationGracePeriodSeconds: 120
        volumes:
        - name: config-volume
          secret:
            defaultMode: 420
            secretName: alertmanager-prometheus-kube-prometheus-alertmanager-generated
        - name: tls-assets
          projected:
            defaultMode: 420
            sources:
            - secret:
                name: alertmanager-prometheus-kube-prometheus-alertmanager-tls-assets-0
        - emptyDir:
            medium: Memory
          name: config-out
        - name: web-config
          secret:
            defaultMode: 420
            secretName: alertmanager-prometheus-kube-prometheus-alertmanager-web-config
        - emptyDir: {}
          name: alertmanager-prometheus-kube-prometheus-alertmanager-db
    updateStrategy:
      type: RollingUpdate
  status:
    availableReplicas: 1
    collisionCount: 0
    currentReplicas: 1
    currentRevision: alertmanager-prometheus-kube-prometheus-alertmanager-7cbc9fffbc
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updateRevision: alertmanager-prometheus-kube-prometheus-alertmanager-7cbc9fffbc
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: StatefulSet
  metadata:
    annotations:
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
      prometheus-operator-input-hash: "10052739302978650686"
    creationTimestamp: "2024-08-08T17:00:01Z"
    generation: 1
    labels:
      app: kube-prometheus-stack-prometheus
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/part-of: kube-prometheus-stack
      app.kubernetes.io/version: 61.7.2
      chart: kube-prometheus-stack-61.7.2
      heritage: Helm
      managed-by: prometheus-operator
      operator.prometheus.io/mode: server
      operator.prometheus.io/name: prometheus-kube-prometheus-prometheus
      operator.prometheus.io/shard: "0"
      release: prometheus
    name: prometheus-prometheus-kube-prometheus-prometheus
    namespace: monitoring
    ownerReferences:
    - apiVersion: monitoring.coreos.com/v1
      blockOwnerDeletion: true
      controller: true
      kind: Prometheus
      name: prometheus-kube-prometheus-prometheus
      uid: 3454c7cc-839a-4035-9575-11fb656bf1f0
    resourceVersion: "19780"
    uid: 33ad9af7-127c-42f9-94c7-a0bfdbeb5d67
  spec:
    persistentVolumeClaimRetentionPolicy:
      whenDeleted: Retain
      whenScaled: Retain
    podManagementPolicy: Parallel
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app.kubernetes.io/instance: prometheus-kube-prometheus-prometheus
        app.kubernetes.io/managed-by: prometheus-operator
        app.kubernetes.io/name: prometheus
        operator.prometheus.io/name: prometheus-kube-prometheus-prometheus
        operator.prometheus.io/shard: "0"
        prometheus: prometheus-kube-prometheus-prometheus
    serviceName: prometheus-operated
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/default-container: prometheus
        creationTimestamp: null
        labels:
          app.kubernetes.io/instance: prometheus-kube-prometheus-prometheus
          app.kubernetes.io/managed-by: prometheus-operator
          app.kubernetes.io/name: prometheus
          app.kubernetes.io/version: 2.53.1
          operator.prometheus.io/name: prometheus-kube-prometheus-prometheus
          operator.prometheus.io/shard: "0"
          prometheus: prometheus-kube-prometheus-prometheus
      spec:
        automountServiceAccountToken: true
        containers:
        - args:
          - --web.console.templates=/etc/prometheus/consoles
          - --web.console.libraries=/etc/prometheus/console_libraries
          - --config.file=/etc/prometheus/config_out/prometheus.env.yaml
          - --web.enable-lifecycle
          - --web.external-url=http://prometheus-kube-prometheus-prometheus.monitoring:9090
          - --web.route-prefix=/
          - --storage.tsdb.retention.time=10d
          - --storage.tsdb.path=/prometheus
          - --storage.tsdb.wal-compression
          - --web.config.file=/etc/prometheus/web_config/web-config.yaml
          image: quay.io/prometheus/prometheus:v2.53.1
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 6
            httpGet:
              path: /-/healthy
              port: http-web
              scheme: HTTP
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 3
          name: prometheus
          ports:
          - containerPort: 9090
            name: http-web
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /-/ready
              port: http-web
              scheme: HTTP
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 3
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          startupProbe:
            failureThreshold: 60
            httpGet:
              path: /-/ready
              port: http-web
              scheme: HTTP
            periodSeconds: 15
            successThreshold: 1
            timeoutSeconds: 3
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: FallbackToLogsOnError
          volumeMounts:
          - mountPath: /etc/prometheus/config_out
            name: config-out
            readOnly: true
          - mountPath: /etc/prometheus/certs
            name: tls-assets
            readOnly: true
          - mountPath: /prometheus
            name: prometheus-prometheus-kube-prometheus-prometheus-db
          - mountPath: /etc/prometheus/rules/prometheus-prometheus-kube-prometheus-prometheus-rulefiles-0
            name: prometheus-prometheus-kube-prometheus-prometheus-rulefiles-0
          - mountPath: /etc/prometheus/web_config/web-config.yaml
            name: web-config
            readOnly: true
            subPath: web-config.yaml
        - args:
          - --listen-address=:8080
          - --reload-url=http://127.0.0.1:9090/-/reload
          - --config-file=/etc/prometheus/config/prometheus.yaml.gz
          - --config-envsubst-file=/etc/prometheus/config_out/prometheus.env.yaml
          - --watched-dir=/etc/prometheus/rules/prometheus-prometheus-kube-prometheus-prometheus-rulefiles-0
          command:
          - /bin/prometheus-config-reloader
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: SHARD
            value: "0"
          image: quay.io/prometheus-operator/prometheus-config-reloader:v0.75.2
          imagePullPolicy: IfNotPresent
          name: config-reloader
          ports:
          - containerPort: 8080
            name: reloader-web
            protocol: TCP
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: FallbackToLogsOnError
          volumeMounts:
          - mountPath: /etc/prometheus/config
            name: config
          - mountPath: /etc/prometheus/config_out
            name: config-out
          - mountPath: /etc/prometheus/rules/prometheus-prometheus-kube-prometheus-prometheus-rulefiles-0
            name: prometheus-prometheus-kube-prometheus-prometheus-rulefiles-0
        dnsPolicy: ClusterFirst
        initContainers:
        - args:
          - --watch-interval=0
          - --listen-address=:8081
          - --config-file=/etc/prometheus/config/prometheus.yaml.gz
          - --config-envsubst-file=/etc/prometheus/config_out/prometheus.env.yaml
          - --watched-dir=/etc/prometheus/rules/prometheus-prometheus-kube-prometheus-prometheus-rulefiles-0
          command:
          - /bin/prometheus-config-reloader
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: SHARD
            value: "0"
          image: quay.io/prometheus-operator/prometheus-config-reloader:v0.75.2
          imagePullPolicy: IfNotPresent
          name: init-config-reloader
          ports:
          - containerPort: 8081
            name: reloader-web
            protocol: TCP
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: FallbackToLogsOnError
          volumeMounts:
          - mountPath: /etc/prometheus/config
            name: config
          - mountPath: /etc/prometheus/config_out
            name: config-out
          - mountPath: /etc/prometheus/rules/prometheus-prometheus-kube-prometheus-prometheus-rulefiles-0
            name: prometheus-prometheus-kube-prometheus-prometheus-rulefiles-0
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 2000
          runAsGroup: 2000
          runAsNonRoot: true
          runAsUser: 1000
          seccompProfile:
            type: RuntimeDefault
        serviceAccount: prometheus-kube-prometheus-prometheus
        serviceAccountName: prometheus-kube-prometheus-prometheus
        shareProcessNamespace: false
        terminationGracePeriodSeconds: 600
        volumes:
        - name: config
          secret:
            defaultMode: 420
            secretName: prometheus-prometheus-kube-prometheus-prometheus
        - name: tls-assets
          projected:
            defaultMode: 420
            sources:
            - secret:
                name: prometheus-prometheus-kube-prometheus-prometheus-tls-assets-0
        - emptyDir:
            medium: Memory
          name: config-out
        - configMap:
            defaultMode: 420
            name: prometheus-prometheus-kube-prometheus-prometheus-rulefiles-0
          name: prometheus-prometheus-kube-prometheus-prometheus-rulefiles-0
        - name: web-config
          secret:
            defaultMode: 420
            secretName: prometheus-prometheus-kube-prometheus-prometheus-web-config
        - emptyDir: {}
          name: prometheus-prometheus-kube-prometheus-prometheus-db
    updateStrategy:
      type: RollingUpdate
  status:
    availableReplicas: 1
    collisionCount: 0
    currentReplicas: 1
    currentRevision: prometheus-prometheus-kube-prometheus-prometheus-545cdf7b5b
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updateRevision: prometheus-prometheus-kube-prometheus-prometheus-545cdf7b5b
    updatedReplicas: 1
- apiVersion: batch/v1
  kind: Job
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"batch/v1","kind":"Job","metadata":{"annotations":{},"labels":{"app.kubernetes.io/component":"admission-webhook","app.kubernetes.io/instance":"ingress-nginx","app.kubernetes.io/name":"ingress-nginx"},"name":"ingress-nginx-admission-create","namespace":"ingress-nginx"},"spec":{"template":{"metadata":{"labels":{"app.kubernetes.io/component":"admission-webhook","app.kubernetes.io/instance":"ingress-nginx","app.kubernetes.io/name":"ingress-nginx"},"name":"ingress-nginx-admission-create"},"spec":{"containers":[{"args":["create","--host=ingress-nginx-controller-admission,ingress-nginx-controller-admission.$(POD_NAMESPACE).svc","--namespace=$(POD_NAMESPACE)","--secret-name=ingress-nginx-admission"],"env":[{"name":"POD_NAMESPACE","valueFrom":{"fieldRef":{"fieldPath":"metadata.namespace"}}}],"image":"registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.4.1@sha256:36d05b4077fb8e3d13663702fa337f124675ba8667cbd949c03a8e8ea6fa4366","imagePullPolicy":"IfNotPresent","name":"create","securityContext":{"allowPrivilegeEscalation":false}}],"nodeSelector":{"kubernetes.io/os":"linux","minikube.k8s.io/primary":"true"},"restartPolicy":"OnFailure","securityContext":{"runAsNonRoot":true,"runAsUser":2000},"serviceAccountName":"ingress-nginx-admission"}}}}
    creationTimestamp: "2024-08-08T16:24:08Z"
    generation: 1
    labels:
      app.kubernetes.io/component: admission-webhook
      app.kubernetes.io/instance: ingress-nginx
      app.kubernetes.io/name: ingress-nginx
    name: ingress-nginx-admission-create
    namespace: ingress-nginx
    resourceVersion: "12187"
    uid: f8296098-5c81-40c6-b81f-4b2d97c8be53
  spec:
    backoffLimit: 6
    completionMode: NonIndexed
    completions: 1
    manualSelector: false
    parallelism: 1
    podReplacementPolicy: TerminatingOrFailed
    selector:
      matchLabels:
        batch.kubernetes.io/controller-uid: f8296098-5c81-40c6-b81f-4b2d97c8be53
    suspend: false
    template:
      metadata:
        creationTimestamp: null
        labels:
          app.kubernetes.io/component: admission-webhook
          app.kubernetes.io/instance: ingress-nginx
          app.kubernetes.io/name: ingress-nginx
          batch.kubernetes.io/controller-uid: f8296098-5c81-40c6-b81f-4b2d97c8be53
          batch.kubernetes.io/job-name: ingress-nginx-admission-create
          controller-uid: f8296098-5c81-40c6-b81f-4b2d97c8be53
          job-name: ingress-nginx-admission-create
        name: ingress-nginx-admission-create
      spec:
        containers:
        - args:
          - create
          - --host=ingress-nginx-controller-admission,ingress-nginx-controller-admission.$(POD_NAMESPACE).svc
          - --namespace=$(POD_NAMESPACE)
          - --secret-name=ingress-nginx-admission
          env:
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.4.1@sha256:36d05b4077fb8e3d13663702fa337f124675ba8667cbd949c03a8e8ea6fa4366
          imagePullPolicy: IfNotPresent
          name: create
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/os: linux
          minikube.k8s.io/primary: "true"
        restartPolicy: OnFailure
        schedulerName: default-scheduler
        securityContext:
          runAsNonRoot: true
          runAsUser: 2000
        serviceAccount: ingress-nginx-admission
        serviceAccountName: ingress-nginx-admission
        terminationGracePeriodSeconds: 30
  status:
    completionTime: "2024-08-08T16:24:11Z"
    conditions:
    - lastProbeTime: "2024-08-08T16:24:11Z"
      lastTransitionTime: "2024-08-08T16:24:11Z"
      status: "True"
      type: Complete
    ready: 0
    startTime: "2024-08-08T16:24:08Z"
    succeeded: 1
    terminating: 0
    uncountedTerminatedPods: {}
- apiVersion: batch/v1
  kind: Job
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"batch/v1","kind":"Job","metadata":{"annotations":{},"labels":{"app.kubernetes.io/component":"admission-webhook","app.kubernetes.io/instance":"ingress-nginx","app.kubernetes.io/name":"ingress-nginx"},"name":"ingress-nginx-admission-patch","namespace":"ingress-nginx"},"spec":{"template":{"metadata":{"labels":{"app.kubernetes.io/component":"admission-webhook","app.kubernetes.io/instance":"ingress-nginx","app.kubernetes.io/name":"ingress-nginx"},"name":"ingress-nginx-admission-patch"},"spec":{"containers":[{"args":["patch","--webhook-name=ingress-nginx-admission","--namespace=$(POD_NAMESPACE)","--patch-mutating=false","--secret-name=ingress-nginx-admission","--patch-failure-policy=Fail"],"env":[{"name":"POD_NAMESPACE","valueFrom":{"fieldRef":{"fieldPath":"metadata.namespace"}}}],"image":"registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.4.1@sha256:36d05b4077fb8e3d13663702fa337f124675ba8667cbd949c03a8e8ea6fa4366","imagePullPolicy":"IfNotPresent","name":"patch","securityContext":{"allowPrivilegeEscalation":false}}],"nodeSelector":{"kubernetes.io/os":"linux","minikube.k8s.io/primary":"true"},"restartPolicy":"OnFailure","securityContext":{"runAsNonRoot":true,"runAsUser":2000},"serviceAccountName":"ingress-nginx-admission"}}}}
    creationTimestamp: "2024-08-08T16:24:08Z"
    generation: 1
    labels:
      app.kubernetes.io/component: admission-webhook
      app.kubernetes.io/instance: ingress-nginx
      app.kubernetes.io/name: ingress-nginx
    name: ingress-nginx-admission-patch
    namespace: ingress-nginx
    resourceVersion: "12194"
    uid: 1deee006-032e-4a76-aeba-46e7e12ddb68
  spec:
    backoffLimit: 6
    completionMode: NonIndexed
    completions: 1
    manualSelector: false
    parallelism: 1
    podReplacementPolicy: TerminatingOrFailed
    selector:
      matchLabels:
        batch.kubernetes.io/controller-uid: 1deee006-032e-4a76-aeba-46e7e12ddb68
    suspend: false
    template:
      metadata:
        creationTimestamp: null
        labels:
          app.kubernetes.io/component: admission-webhook
          app.kubernetes.io/instance: ingress-nginx
          app.kubernetes.io/name: ingress-nginx
          batch.kubernetes.io/controller-uid: 1deee006-032e-4a76-aeba-46e7e12ddb68
          batch.kubernetes.io/job-name: ingress-nginx-admission-patch
          controller-uid: 1deee006-032e-4a76-aeba-46e7e12ddb68
          job-name: ingress-nginx-admission-patch
        name: ingress-nginx-admission-patch
      spec:
        containers:
        - args:
          - patch
          - --webhook-name=ingress-nginx-admission
          - --namespace=$(POD_NAMESPACE)
          - --patch-mutating=false
          - --secret-name=ingress-nginx-admission
          - --patch-failure-policy=Fail
          env:
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.4.1@sha256:36d05b4077fb8e3d13663702fa337f124675ba8667cbd949c03a8e8ea6fa4366
          imagePullPolicy: IfNotPresent
          name: patch
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/os: linux
          minikube.k8s.io/primary: "true"
        restartPolicy: OnFailure
        schedulerName: default-scheduler
        securityContext:
          runAsNonRoot: true
          runAsUser: 2000
        serviceAccount: ingress-nginx-admission
        serviceAccountName: ingress-nginx-admission
        terminationGracePeriodSeconds: 30
  status:
    completionTime: "2024-08-08T16:24:12Z"
    conditions:
    - lastProbeTime: "2024-08-08T16:24:12Z"
      lastTransitionTime: "2024-08-08T16:24:12Z"
      status: "True"
      type: Complete
    ready: 0
    startTime: "2024-08-08T16:24:08Z"
    succeeded: 1
    terminating: 0
    uncountedTerminatedPods: {}
kind: List
metadata:
  resourceVersion: ""
